import os
import json
import random
import torch
import torch.nn.functional as F
from kaldi_io import read_mat_scp


def create_data_folder(feats_path, out_path):
    """
    Takes Kaldi file containing acoustic features (*.scp format) and extracts samples in the specified directory. Separate
    file is created for every sample. Filename format is "fileId_sequenceLength".
    """

    for i, (sample_id, sample) in enumerate(read_mat_scp(feats_path)):
        with open(os.path.join(out_path, '%s_%s' % (sample_id, sample.shape[0])), 'w+') as f:
            f.write(json.dumps(sample.tolist()))

def split_data(data_path, splits, shuffle=True, savepath=None):
    """
    Takes data folder and splits it into train/dev/test sets.
    :param data_path: Path to the folder where data samples are kept (i.e. folder generated by calling create_data_folder function)
    :param splits: list containint exactly 3 values which sum up to 1. These are proportions of the splits accordingly.
    :param shuffle: If True, data is shuffled.
    :param savepath: Optional output directory to save the splits.
    :return: dictionary containing the splits.
    """

    if len(splits) != 3:
        raise ValueError("Splits must contain 3 elements")

    if sum(splits) != 1:
        raise ValueError("Splits must sum up to 1")
        
    sample_ids = os.listdir(data_path)
        
    if shuffle:
        random.shuffle(sample_ids)
        
    l = int(splits[0] * len(sample_ids))
    r = int(splits[1] * len(sample_ids))
        
    trn = sorted(sample_ids[0:l],   key=lambda x: int(x.split('_')[1]))
    dev = sorted(sample_ids[l:l+r], key=lambda x: int(x.split('_')[1]))
    tst = sorted(sample_ids[l+r:],  key=lambda x: int(x.split('_')[1]))

    if savepath:
        for filename, data in [('trn_ids', trn), ('dev_ids', dev), ('tst_ids', tst)]:
            with open(os.path.join(savepath, filename), 'w+') as f:
                f.write("\n".join(data) + "\n")

    return {'train': trn, 'dev': dev, 'tst': tst}
        

class SpeechDataset:
    """Defines an iterator over the dataset. This class is intended to be used with PyTorch DataLoader"""
    
    def __init__(self, data_path, sample_ids):
        
        self.data_path = data_path

        if isinstance(sample_ids, list):
            self._datafiles = sample_ids
        else:
            with open(sample_ids) as f:
                self._datafiles = [x.strip() for x in f.readlines()]
        
    def __getitem__(self, index):
             
        with open(os.path.join(self.data_path, self._datafiles[index])) as f:
            sample = json.load(f)

        return torch.FloatTensor(sample)
                      
    def __len__(self):
        
        return len(self._datafiles)
        

def collate_fn(batch):
    """This function takes list of samples and assembles a batch. It is intended to used in PyTorch DataLoader."""

    max_seq_len = max(x.size(0) for x in batch)
       
    res = torch.FloatTensor(len(batch), max_seq_len, batch[0].size(1))

    for i, x in enumerate(batch):
        res[i, :] = F.pad(x, (0, 0, 0, max_seq_len - x.size(0))).data
            
    return res
