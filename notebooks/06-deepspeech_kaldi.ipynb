{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deepspeech with kaldi features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from warpctc_pytorch import CTCLoss\n",
    "#torch.multiprocessing.set_start_method(\"spawn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restart from here\n",
    "DEV = True\n",
    "EPOCHS = 1\n",
    "\n",
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "True# autoreloads\n",
    "%reload_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport parameters\n",
    "\n",
    "# Allows to load modules from parent directory\n",
    "from time import time\n",
    "import inspect, sys, os, json\n",
    "from os.path import dirname, abspath\n",
    "sys.path.append(dirname(dirname(abspath(inspect.getfile(inspect.currentframe())))))\n",
    "\n",
    "from pathlib import Path\n",
    "from os import makedirs\n",
    "from collections import OrderedDict\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from data.data_loader import create_binarizer, get_accents_counts\n",
    "from utils import count_parameters\n",
    "from models.modules import MaskConv, SequenceWise, BatchRNN, InferenceBatchSoftmax, Lookahead, \\\n",
    "                    supported_rnns, supported_rnns_inv\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import math\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from decoder import GreedyDecoder, BeamCTCDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = parameters.get_parameters(dev=DEV, epochs=EPOCHS, us_en=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_cnts(list_):\n",
    "    return pd.Series(list_).value_counts()\n",
    "\n",
    "def extract_num (s):\n",
    "    return ''.join([c if c.isdigit() else '' for c in s])\n",
    "\n",
    "def ids_list(manifest):\n",
    "    ids = []\n",
    "    with open(manifest) as f:\n",
    "        for l in f:\n",
    "            s = l.split('/')\n",
    "            ids.append(f'{s[3]}-{s[5].split(\".\")[0]}')\n",
    "    return ids\n",
    "\n",
    "def make_accent_dict(manifest_path):\n",
    "    accent_dict = {}\n",
    "    class_dict = {}\n",
    "    with open(manifest_path) as f:\n",
    "        for l in f:\n",
    "            wav, txt, acc = l.split(',')\n",
    "            num = extract_num(wav)\n",
    "            accent = acc.strip()\n",
    "            if accent not in class_dict:\n",
    "                new_key = 0 if (len(class_dict) == 0) else max(class_dict.values()) + 1\n",
    "                class_dict[accent] = new_key\n",
    "            accent_dict[num] = class_dict[accent]\n",
    "    return accent_dict, {v: k for k, v in class_dict.items()}\n",
    "\n",
    "def tile(a, dim, n_tile):\n",
    "    init_dim = a.size(dim)\n",
    "    repeat_idx = [1] * a.dim()\n",
    "    repeat_idx[dim] = n_tile\n",
    "    a = a.repeat(*(repeat_idx))\n",
    "    order_index = torch.LongTensor(np.concatenate([init_dim * np.arange(n_tile) + i for i in range(init_dim)]))\n",
    "    return torch.index_select(a, dim, order_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KaldiDeepspeechDataset(Dataset):\n",
    "    \"\"\"Defines an iterator over the dataset. This class is intended to be used with PyTorch DataLoader\"\"\"\n",
    "    \n",
    "    def __init__(self, data_path, labels, sample_ids, transcripts_path,\n",
    "                 accent_id_dict, ivectors_path=None):\n",
    "        \n",
    "        self.data_path = data_path\n",
    "        self.ivectors_path = ivectors_path\n",
    "        self.transcripts_path = transcripts_path\n",
    "        self.accent_id_dict = accent_id_dict\n",
    "        self.labels_map = dict([(labels[i], i) for i in range(len(labels))])\n",
    "        if isinstance(sample_ids, list):\n",
    "            self._datafiles = sample_ids\n",
    "        else:\n",
    "            with open(sample_ids) as f:\n",
    "                self._datafiles = [x.strip() for x in f.readlines()]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        file_idx = self._datafiles[index]\n",
    "        with open(os.path.join(self.data_path, file_idx)) as f:\n",
    "            sample = json.load(f)\n",
    "        sample = torch.FloatTensor(sample)\n",
    "        \n",
    "        target = self.accent_id_dict[extract_num(self._datafiles[index])]\n",
    "        \n",
    "        s_id = file_idx.split('-')[-1]\n",
    "\n",
    "        transcript_path = f'{self.transcripts_path}sample-{s_id}.txt'\n",
    "        transcript = self.parse_transcript(transcript_path)\n",
    "        \n",
    "        if self.ivectors_path is None:\n",
    "            return torch.FloatTensor(sample), target, transcript\n",
    "        else:\n",
    "            with open(os.path.join(self.ivectors_path, self._datafiles[index])) as f:\n",
    "                ivect = json.load(f)\n",
    "            return torch.FloatTensor(sample), target, transcript, torch.FloatTensor(ivect)\n",
    "        \n",
    "    def parse_transcript(self, transcript_path):\n",
    "        with open(transcript_path, 'r', encoding='utf8') as transcript_file:\n",
    "            transcript = transcript_file.read().replace('\\n', '')\n",
    "        transcript = list(filter(None, [self.labels_map.get(x) for x in list(transcript)]))\n",
    "        return transcript\n",
    "                      \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self._datafiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch_tot):\n",
    "    \"\"\"This function takes list of samples and assembles a batch. It is intended to used in PyTorch DataLoader.\"\"\"\n",
    "    batch = list(zip(*batch_tot))\n",
    "    ivect = None\n",
    "    \n",
    "    if len(batch) == 3:\n",
    "        input_, acc, trs = batch\n",
    "    elif len(batch) == 4:\n",
    "        input_, acc, trs, ivect = batch\n",
    "\n",
    "    input_lens = torch.tensor([len(r) for r in input_])\n",
    "    acc = torch.tensor(acc)\n",
    "    \n",
    "    input_ = nn.utils.rnn.pad_sequence(input_, batch_first=True)\n",
    "\n",
    "    target_lens = torch.tensor([len(t) for t in trs])\n",
    "\n",
    "    if ivect is not None:\n",
    "        ivect = nn.utils.rnn.pad_sequence(ivect, batch_first=True)\n",
    "        ivect = tile(ivect, 1, 10)\n",
    "        ivect = ivect[:, :input_.size(1), :]\n",
    "        input_ = torch.cat([input_, ivect], dim=2)\n",
    "    \n",
    "    __, idx = input_lens.sort(descending=True)\n",
    "    \n",
    "    targets = np.array(trs)[idx]\n",
    "    targets = torch.tensor([t for target in targets for t in target])\n",
    "\n",
    "    return input_[idx], input_lens[idx].int(), targets.int(), target_lens[idx].int(), acc[idx].int()\n",
    "\n",
    "class KaldiDeepspeechDataLoader(DataLoader):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Creates a data loader for SpeechDatasets.\n",
    "        \"\"\"\n",
    "        super(KaldiDeepspeechDataLoader, self).__init__(*args, **kwargs)\n",
    "        self.collate_fn = collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "accent_id_dict, accent_dict = make_accent_dict(param['train_manifest'])\n",
    "\n",
    "train_dataset = KaldiDeepspeechDataset(data_path=param['train_kaldi'],\n",
    "                              labels=param['labels'],\n",
    "                              sample_ids=ids_list(param['train_manifest']), \n",
    "                              transcripts_path=param['train_transcripts'],\n",
    "                              accent_id_dict=accent_id_dict,\n",
    "                              ivectors_path=param['train_ivectors'])\n",
    "\n",
    "train_loader = KaldiDeepspeechDataLoader(train_dataset, \n",
    "                                shuffle=True, \n",
    "                                num_workers=0,#param['num_worker'],\n",
    "                                batch_size=param['batch_size'])\n",
    "\n",
    "# for data in train_loader:    \n",
    "#     split_targets = []\n",
    "#     offset = 0\n",
    "#     for size in data[3]:\n",
    "#         split_targets.append(data[2][offset:offset + size])\n",
    "#         offset += size\n",
    "#     target_strings = decoder.convert_to_strings(split_targets)\n",
    "#     print('TARGETS', target_strings)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict, __ = make_accent_dict(param['test_manifest'])\n",
    "\n",
    "test_dataset = KaldiDeepspeechDataset(data_path=param['test_kaldi'],\n",
    "                              labels=param['labels'],\n",
    "                              sample_ids=ids_list(param['test_manifest']), \n",
    "                              transcripts_path=param['test_transcripts'],\n",
    "                              accent_id_dict=test_dict,\n",
    "                              ivectors_path=param['test_ivectors'])\n",
    "\n",
    "test_loader = KaldiDeepspeechDataLoader(test_dataset, \n",
    "                                shuffle=True, \n",
    "                                num_workers=param['num_worker'],\n",
    "                                batch_size=param['batch_size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepSpeech(nn.Module):\n",
    "    def __init__(self, \n",
    "                rnn_type=nn.LSTM, \n",
    "                labels=\"abc\", \n",
    "                rnn_hidden_size=768, \n",
    "                nb_layers=5, \n",
    "                audio_conf=None,\n",
    "                bidirectional=True,\n",
    "                DEBUG=False):\n",
    "\n",
    "        super(DeepSpeech, self).__init__()\n",
    "\n",
    "        # model metadata needed for serialization/deserialization\n",
    "        if audio_conf is None:\n",
    "            audio_conf = {}\n",
    "        self._DEBUG = DEBUG\n",
    "        self._version = '0.0.1'\n",
    "        self._hidden_size = rnn_hidden_size\n",
    "        self._nb_layers = nb_layers\n",
    "        self._rnn_type = rnn_type\n",
    "        self._audio_conf = audio_conf or {}\n",
    "        self._labels = labels\n",
    "        self._bidirectional = bidirectional\n",
    "\n",
    "        sample_rate = self._audio_conf.get(\"sample_rate\", 16000)\n",
    "        window_size = self._audio_conf.get(\"window_size\", 0.02)\n",
    "        num_classes = len(self._labels)\n",
    "\n",
    "        self.conv = MaskConv(nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=(41, 11), stride=(2, 2), padding=(20, 5)),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Hardtanh(0, 20, inplace=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=(21, 11), stride=(2, 1), padding=(10, 5)),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Hardtanh(0, 20, inplace=True)\n",
    "        ))\n",
    "\n",
    "        rnn_input_size = 1120\n",
    "\n",
    "        rnns = []\n",
    "        rnn = BatchRNN(input_size=rnn_input_size, hidden_size=rnn_hidden_size, rnn_type=rnn_type,\n",
    "                       bidirectional=bidirectional, batch_norm=False)\n",
    "        rnns.append(('0', rnn))\n",
    "        for x in range(nb_layers - 1):\n",
    "            rnn = BatchRNN(input_size=rnn_hidden_size, hidden_size=rnn_hidden_size, rnn_type=rnn_type,\n",
    "                           bidirectional=bidirectional)\n",
    "            rnns.append(('%d' % (x + 1), rnn))\n",
    "        self.rnns = nn.Sequential(OrderedDict(rnns))\n",
    "\n",
    "        fully_connected = nn.Sequential(\n",
    "            nn.BatchNorm1d(rnn_hidden_size),\n",
    "            nn.Linear(rnn_hidden_size, num_classes, bias=False)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            SequenceWise(fully_connected),\n",
    "        )\n",
    "        self.inference_softmax = InferenceBatchSoftmax()\n",
    "\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        if self._DEBUG:\n",
    "            print('input', x.size())\n",
    "\n",
    "        lengths = lengths.cpu().int()\n",
    "        output_lengths = self.get_seq_lens(lengths)\n",
    "        \n",
    "        x = x.view(x.size(0), 1, x.size(1), x.size(2))\n",
    "        x = x.transpose(2, 3)\n",
    "        if self._DEBUG:\n",
    "            print('after view transpose', x.size())\n",
    "            \n",
    "        x, _ = self.conv(x, output_lengths)\n",
    "        if self._DEBUG:\n",
    "            print('after conv', x.size())\n",
    "\n",
    "        sizes = x.size()\n",
    "        x = x.view(sizes[0], sizes[1] * sizes[2], sizes[3])  # Collapse feature dimension\n",
    "        x = x.transpose(1, 2).transpose(0, 1).contiguous()  # TxNxH\n",
    "        if self._DEBUG:\n",
    "            print('after view transpose', x.size())\n",
    "\n",
    "        for rnn in self.rnns:\n",
    "            x = rnn(x, output_lengths)\n",
    "        if self._DEBUG:\n",
    "            print('after rnn', x.size())\n",
    "\n",
    "        x = self.fc(x)\n",
    "        if self._DEBUG:\n",
    "            print('after fc', x.size())\n",
    "        \n",
    "        x = x.transpose(0, 1)\n",
    "        if self._DEBUG:\n",
    "            print('after transpose', x.size())\n",
    "        # identity in training mode, softmax in eval mode\n",
    "        x = self.inference_softmax(x)\n",
    "        if self._DEBUG:\n",
    "            print('after softmax', x.size())\n",
    "            \n",
    "        x = x.transpose(0, 1)\n",
    "        if self._DEBUG:\n",
    "            print('after transpose', x.size())\n",
    "            \n",
    "        self._DEBUG = False\n",
    "        return x, output_lengths\n",
    "\n",
    "    def get_seq_lens(self, input_length):\n",
    "        \"\"\"\n",
    "        Given a 1D Tensor or Variable containing integer sequence lengths, return a 1D tensor or variable\n",
    "        containing the size sequences that will be output by the network.\n",
    "        :param input_length: 1D Tensor\n",
    "        :return: 1D Tensor scaled by model\n",
    "        \"\"\"\n",
    "        seq_len = input_length\n",
    "        for m in self.conv.modules():\n",
    "            if type(m) == nn.modules.conv.Conv2d:\n",
    "                seq_len = ((seq_len + 2 * m.padding[1] - m.dilation[1] * (m.kernel_size[1] - 1) - 1) / m.stride[1] + 1)\n",
    "        return seq_len.int()\n",
    "\n",
    "    @staticmethod\n",
    "    def get_labels(model):\n",
    "        return model.module._labels if model.is_parallel(model) else model._labels\n",
    "\n",
    "    @staticmethod\n",
    "    def get_param_size(model):\n",
    "        params = 0\n",
    "        for p in model.parameters():\n",
    "            tmp = 1\n",
    "            for x in p.size():\n",
    "                tmp *= x\n",
    "            params += tmp\n",
    "        return params\n",
    "\n",
    "    @staticmethod\n",
    "    def get_audio_conf(model):\n",
    "        return model.module._audio_conf if DeepSpeech.is_parallel(model) else model._audio_conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepSpeech(\n",
      "  (conv): MaskConv(\n",
      "    (seq_module): Sequential(\n",
      "      (0): Conv2d(1, 32, kernel_size=(41, 11), stride=(2, 2), padding=(20, 5))\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): Hardtanh(min_val=0, max_val=20, inplace)\n",
      "      (3): Conv2d(32, 32, kernel_size=(21, 11), stride=(2, 1), padding=(10, 5))\n",
      "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): Hardtanh(min_val=0, max_val=20, inplace)\n",
      "    )\n",
      "  )\n",
      "  (rnns): Sequential(\n",
      "    (0): BatchRNN(\n",
      "      (rnn): GRU(1120, 40, bidirectional=True)\n",
      "    )\n",
      "    (1): BatchRNN(\n",
      "      (batch_norm): SequenceWise (\n",
      "      BatchNorm1d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))\n",
      "      (rnn): GRU(40, 40, bidirectional=True)\n",
      "    )\n",
      "    (2): BatchRNN(\n",
      "      (batch_norm): SequenceWise (\n",
      "      BatchNorm1d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))\n",
      "      (rnn): GRU(40, 40, bidirectional=True)\n",
      "    )\n",
      "    (3): BatchRNN(\n",
      "      (batch_norm): SequenceWise (\n",
      "      BatchNorm1d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))\n",
      "      (rnn): GRU(40, 40, bidirectional=True)\n",
      "    )\n",
      "    (4): BatchRNN(\n",
      "      (batch_norm): SequenceWise (\n",
      "      BatchNorm1d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))\n",
      "      (rnn): GRU(40, 40, bidirectional=True)\n",
      "    )\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): SequenceWise (\n",
      "    Sequential(\n",
      "      (0): BatchNorm1d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): Linear(in_features=40, out_features=29, bias=False)\n",
      "    ))\n",
      "  )\n",
      "  (inference_softmax): InferenceBatchSoftmax()\n",
      ")\n",
      "Model parameters counts: 610328\n"
     ]
    }
   ],
   "source": [
    "model = DeepSpeech(rnn_type=param['rnn_type'], \n",
    "                labels=param['labels'], \n",
    "                rnn_hidden_size=param['rnn_hidden_size'], \n",
    "                nb_layers=param['num_layers'], #audio_conf=audio_conf,\n",
    "                bidirectional=True,\n",
    "                DEBUG=DEBUG,)\n",
    "\n",
    "if param['cuda']:\n",
    "    model.cuda()\n",
    "\n",
    "criterion = CTCLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=param['lr'][0])\n",
    "\n",
    "decoder = BeamCTCDecoder(param['labels'], lm_path=param['lm_path'],\n",
    "                        alpha=0.8, beta=1.,\n",
    "                        cutoff_top_n=40, cutoff_prob=1.0,\n",
    "                        beam_width=100, num_processes=param['num_worker'])\n",
    "target_decoder = GreedyDecoder(param['labels'])\n",
    "\n",
    "print(model)\n",
    "print('Model parameters counts:', count_parameters(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_wer(targets, targets_len, out, output_len):\n",
    "    split_targets = []\n",
    "    offset = 0\n",
    "    for size in targets_len:\n",
    "        split_targets.append(targets[offset:offset + size])\n",
    "        offset += size\n",
    "        \n",
    "    decoded_output, _ = decoder.decode(out.data.transpose(0,1), output_len)\n",
    "    target_strings = target_decoder.convert_to_strings(split_targets)\n",
    "    \n",
    "    if False:\n",
    "        print('targets', targets)\n",
    "        print('split_targets', split_targets)\n",
    "        print('out', out)\n",
    "        print('output_len', output_len)\n",
    "        print('decoded', decoded_output)\n",
    "        print('target', target_strings)\n",
    "    \n",
    "    wer, cer = 0, 0\n",
    "    for x in range(len(target_strings)):\n",
    "        transcript, reference = decoded_output[x][0], target_strings[x][0]\n",
    "        wer += decoder.wer(transcript, reference) / float(len(reference.split()))\n",
    "        #cer += decoder.cer(transcript, reference) / float(len(reference))\n",
    "    wer /= len(target_strings)\n",
    "    return wer * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs, \n",
    "          model, \n",
    "          train_loader, \n",
    "          test_loader, \n",
    "          optimizer, \n",
    "          silent=True,\n",
    "          exp_name='__tmp__'):\n",
    "\n",
    "    # Tensorboard\n",
    "    tb_path = Path(param['tensorboard_dir']) / exp_name\n",
    "    makedirs(tb_path, exist_ok=True)\n",
    "    tb_writer = SummaryWriter(tb_path)\n",
    "    best_model = model\n",
    "    \n",
    "    prev_epoch_val_loss = math.inf\n",
    "    prev_wer = math.inf\n",
    "    \n",
    "    ## Train\n",
    "    for epoch in range(1, param['epochs'] + 1):\n",
    "        import gc; gc.collect()\n",
    "        print('')\n",
    "        print(f'## EPOCH {epoch} ##')\n",
    "        print(f'Training:')\n",
    "        model.train()\n",
    "\n",
    "        # train\n",
    "        epoch_losses = []\n",
    "        for i, data in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "            inputs, inputs_len, targets, targets_len, target_accents = data\n",
    "            \n",
    "            inputs = inputs.cuda()\n",
    "            inputs_len = inputs_len.cuda()\n",
    "            targets = targets.cuda()\n",
    "            targets_len = targets_len.cuda()\n",
    "            target_accents = target_accents.cuda()\n",
    "\n",
    "            # Forward pass\n",
    "            out, output_len = model(inputs, inputs_len)\n",
    "\n",
    "            out = out.cpu()\n",
    "            targets = targets.cpu()\n",
    "            targets_len = targets_len.cpu()\n",
    "            \n",
    "            if DEBUG:\n",
    "                print('## Outputs train')\n",
    "                print('out', out.size())\n",
    "                print('targets', targets.size())\n",
    "                print('output_len', output_len.size())\n",
    "                print('targets_len', targets_len.size())\n",
    "                   \n",
    "            loss = criterion(out, targets, output_len, targets_len)\n",
    "            epoch_losses.append(loss)\n",
    "\n",
    "            if not silent:\n",
    "                print(f'Iteration {i+1}/{len(train_loader):<4}loss: {loss.item():0.3f}')\n",
    "\n",
    "            # Gradient\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        epoch_loss = sum(epoch_losses) / len(train_loader)\n",
    "        tb_writer.add_scalar('stats/train_loss', epoch_loss, epoch)\n",
    "        print(f'Epoch {epoch} average loss: {epoch_loss.item():0.3f}')\n",
    "\n",
    "        # validate\n",
    "        print(f'Testing:')\n",
    "        model.eval()\n",
    "        epoch_val_losses = []\n",
    "        epoch_wer = []\n",
    "        with torch.no_grad():\n",
    "            for data in tqdm(test_loader, total=len(test_loader)): ## ## \n",
    "                inputs, inputs_len, targets, targets_len, target_accents = data\n",
    "                \n",
    "                inputs = inputs.cuda()\n",
    "                inputs_len = inputs_len.cuda()\n",
    "                targets = targets.cuda()\n",
    "                targets_len = targets_len.cuda()\n",
    "                target_accents = target_accents.cuda()\n",
    "\n",
    "                out, output_len = model(inputs, inputs_len)\n",
    "\n",
    "                out = out.cpu()\n",
    "                targets = targets.cpu()\n",
    "                targets_len = targets_len.cpu()\n",
    "                \n",
    "                if False:\n",
    "                    print('## Outputs test')\n",
    "                    print('out', out)\n",
    "                    print('targets', targets)\n",
    "                    print('output_len', output_len)\n",
    "                    print('targets_len', targets_len)\n",
    "                \n",
    "                val_loss = criterion(out, targets, output_len, targets_len)\n",
    "                \n",
    "                if DEBUG:\n",
    "                    print('val loss', val_loss)\n",
    "                \n",
    "                epoch_val_losses.append(val_loss)\n",
    "\n",
    "                wer = check_wer(targets, targets_len, out, output_len)\n",
    "                epoch_wer.append(wer)\n",
    "\n",
    "        epoch_val_loss = sum(epoch_val_losses) / len(epoch_val_losses) ##\n",
    "        epoch_wer = sum(epoch_wer) / len(epoch_wer)\n",
    "\n",
    "        tb_writer.add_scalar('stats/val_loss', epoch_val_loss, epoch)\n",
    "        print(f'Average validation loss: {val_loss.item():0.3f}')\n",
    "        \n",
    "        tb_writer.add_scalar('stats/wer', epoch_wer, epoch)\n",
    "        print(f'Average wer: {wer:0.3f}%')\n",
    "\n",
    "        if epoch_val_loss < prev_epoch_val_loss:\n",
    "            print('New best model found.')\n",
    "            best_model = model\n",
    "            prev_epoch_val_loss = epoch_val_loss\n",
    "            \n",
    "    return best_model, prev_epoch_val_loss, prev_wer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#############\n",
      "Big_Simple_DeepSpeech_<class 'torch.nn.modules.rnn.GRU'>_hidden-800_1549027115.3728468\n",
      "#############\n",
      "\n",
      "## EPOCH 1 ##\n",
      "Training:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75876fd33e474afc8bd3e2ef3eee64bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=58), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 average loss: 3349.110\n",
      "Testing:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dbccf3587bd40c09ca2335a59dddb10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=57), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average validation loss: 2863.805\n",
      "Average wer: 90.792%\n",
      "New best model found.\n",
      "#############\n",
      "best overall model: Big_Simple_DeepSpeech_<class 'torch.nn.modules.rnn.GRU'>_hidden-800_1549027115.3728468\n"
     ]
    }
   ],
   "source": [
    "best_models = {}\n",
    "\n",
    "settings = {'rnn_type': [nn.GRU],\n",
    "            'rnn_hidden_size': [800],}\n",
    "\n",
    "for _rnn_type in settings['rnn_type']:\n",
    "    for _rnn_hidden_size in settings['rnn_hidden_size']:\n",
    "        exp_name = f'Big_Simple_DeepSpeech_{_rnn_type}_hidden-{_rnn_hidden_size}_{time()}'\n",
    "\n",
    "        model = DeepSpeech(rnn_type=_rnn_type, \n",
    "                        labels=param['labels'], \n",
    "                        rnn_hidden_size=_rnn_hidden_size, \n",
    "                        nb_layers=param['num_layers'], #audio_conf=audio_conf,\n",
    "                        bidirectional=True,\n",
    "                        DEBUG=DEBUG,)\n",
    "\n",
    "        if param['cuda']:\n",
    "            model.cuda()\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=param['lr'][0])\n",
    "\n",
    "        print()\n",
    "        print(f'{\"\":#<13}')\n",
    "        print(exp_name)\n",
    "        print(f'{\"\":#<13}')\n",
    "\n",
    "        model, val_loss, wer = train(param, \n",
    "                                model,\n",
    "                                train_loader, \n",
    "                                test_loader, optimizer, \n",
    "                                exp_name=exp_name)\n",
    "        best_models[exp_name] = (model, val_loss, wer)\n",
    "\n",
    "        \n",
    "print(f'{\"\":#<13}')\n",
    "\n",
    "best_model = None\n",
    "best_name = None\n",
    "prev_v = math.inf\n",
    "for name, (m, v, w) in best_models.items():\n",
    "    if v < prev_v:\n",
    "        best_model = m\n",
    "        best_name = name\n",
    "print(f'best overall model:', best_name) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    np.set_printoptions(precision=2)\n",
    "    plt.figure()\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"black\") #if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = test_loader\n",
    "best_model.eval()\n",
    "\n",
    "y_true, y_pred = [], []\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(loader, total=len(loader)):\n",
    "        inputs, target_accents, lens = data\n",
    "        inputs = inputs.cuda()\n",
    "        target_accents = target_accents.cuda()\n",
    "        \n",
    "        out, __ = best_model(inputs, lens)\n",
    "        \n",
    "        y_true.extend(target_accents)\n",
    "        y_pred.append(np.argmax(out, axis=1))\n",
    "        \n",
    "    y_pred = torch.cat(y_pred)\n",
    "            \n",
    "    y_true_labels = [accent_dict[int(i)] for i in y_true]\n",
    "    y_pred_labels = [accent_dict[int(i)] for i in y_pred]\n",
    "\n",
    "cnf_mat = confusion_matrix(y_true_labels, y_pred_labels, labels=list(accent_dict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cnf_mat, classes=accent_dict.values(), normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_true_labels, y_pred_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA as sklearnPCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def plot_pca(X, y, _dict, projection='PCA', graph_title=''):\n",
    "    if projection == 'PCA':\n",
    "        Y = sklearnPCA(n_components=2).fit_transform(X)\n",
    "    elif projection == 'TSNE':\n",
    "        Y = TSNE(n_components=2).fit_transform(X)\n",
    "    else:\n",
    "        raise ValueError(f'Projection {projection} unkown.')\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    for lab in _dict.values():\n",
    "        plt.scatter(Y[y==lab, 0],\n",
    "                    Y[y==lab, 1],\n",
    "                    label=lab)\n",
    "    plt.xlabel('Principal Component 1')\n",
    "    plt.ylabel('Principal Component 2')\n",
    "    plt.legend(loc='lower left')\n",
    "    plt.tight_layout()\n",
    "    plt.title(f'{projection}: {graph_title}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = test_loader\n",
    "projection = 'PCA'\n",
    "\n",
    "for model_name, (model, val_loss) in best_models.items():\n",
    "    datapoints = []\n",
    "    targets = []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(loader, total=len(loader)):\n",
    "            \n",
    "            inputs, target_accents, lens = data\n",
    "            inputs = inputs.cuda()\n",
    "            __, bn = best_model(inputs, lens)\n",
    "\n",
    "            datapoints.append(bn)\n",
    "            targets.append(target_accents)\n",
    "            \n",
    "    datapoints = torch.cat(datapoints)\n",
    "    targets = torch.cat(targets)\n",
    "    \n",
    "    X = np.asarray(datapoints)\n",
    "    y = np.asarray([accent_dict[t.item()] for t in targets])\n",
    "    \n",
    "    plot_pca(X, y, accent_dict, projection=projection, graph_title=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
