{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_TO_LOAD = 'saved/vac05-ntbk_fm_1.pt'\n",
    "\n",
    "to_test = ['native', 'lnn']\n",
    "test_manif = {t: f'../data/LogiDataset/splits/for_notebooks/{t}.manifest' for t in to_test}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No train set available for LogiDataset. Replaced by the test set.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from warpctc_pytorch import CTCLoss\n",
    "\n",
    "from time import time\n",
    "import inspect, sys, os, json\n",
    "from os.path import dirname, abspath\n",
    "sys.path.append(dirname(dirname(abspath(inspect.getfile(inspect.currentframe())))))\n",
    "\n",
    "from pathlib import Path\n",
    "from os import makedirs\n",
    "from collections import OrderedDict\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from data.data_loader import create_binarizer, get_accents_counts\n",
    "from utils import count_parameters\n",
    "from models.modules import MaskConv, SequenceWise, BatchRNN, InferenceBatchSoftmax, Lookahead, \\\n",
    "                    supported_rnns, supported_rnns_inv\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import math\n",
    "\n",
    "from multitask_loss import MtLoss\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from decoder import GreedyDecoder, BeamCTCDecoder\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport parameters_logi\n",
    "\n",
    "param = parameters_logi.get_parameters(dev=False, epochs=2, us_en=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_cnts(list_):\n",
    "    return pd.Series(list_).value_counts()\n",
    "\n",
    "def extract_num (s):\n",
    "    return ''.join([c if c.isdigit() else '' for c in s])\n",
    "\n",
    "def ids_list(manifest):\n",
    "    ids = []\n",
    "    with open(manifest) as f:\n",
    "        for l in f:\n",
    "            s = l.split('/')\n",
    "            ids.append(f'{s[4][:-7]}')\n",
    "    return ids\n",
    "\n",
    "def make_accent_dict(manifest_path):\n",
    "    accent_dict = {}\n",
    "    class_dict = {}\n",
    "    with open(manifest_path) as f:\n",
    "        for l in f:\n",
    "            wav, txt, acc = l.split(',')\n",
    "            num = extract_num(wav)\n",
    "            accent = acc.strip()\n",
    "            if accent not in class_dict:\n",
    "                new_key = 0 if (len(class_dict) == 0) else max(class_dict.values()) + 1\n",
    "                class_dict[accent] = new_key\n",
    "            accent_dict[num] = class_dict[accent]\n",
    "    return accent_dict, {v: k for k, v in class_dict.items()}\n",
    "\n",
    "def tile(a, dim, n_tile):\n",
    "    init_dim = a.size(dim)\n",
    "    repeat_idx = [1] * a.dim()\n",
    "    repeat_idx[dim] = n_tile\n",
    "    a = a.repeat(*(repeat_idx))\n",
    "    order_index = torch.LongTensor(np.concatenate([init_dim * np.arange(n_tile) + i for i in range(init_dim)]))\n",
    "    if a.is_cuda:\n",
    "        order_index = order_index.cuda()\n",
    "    return torch.index_select(a, dim, order_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KaldiDeepspeechDataset(Dataset):\n",
    "    \"\"\"Defines an iterator over the dataset. This class is intended to be used with PyTorch DataLoader\"\"\"\n",
    "    \n",
    "    def __init__(self, data_path, labels, sample_ids, transcripts_path,\n",
    "                 accent_id_dict,  embeddings_path, ivectors_path=None):\n",
    "        \n",
    "        self.data_path = data_path\n",
    "        self.ivectors_path = ivectors_path\n",
    "        self.transcripts_path = transcripts_path\n",
    "        self.embeddings_path = embeddings_path\n",
    "        self.accent_id_dict = accent_id_dict\n",
    "        self.labels_map = dict([(labels[i], i) for i in range(len(labels))])\n",
    "        if isinstance(sample_ids, list):\n",
    "            self._datafiles = sample_ids\n",
    "        else:\n",
    "            with open(sample_ids) as f:\n",
    "                self._datafiles = [x.strip() for x in f.readlines()]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        file_idx = self._datafiles[index]\n",
    "            \n",
    "        with open(os.path.join(self.data_path, file_idx)) as f:\n",
    "            sample = json.load(f)\n",
    "        sample = torch.FloatTensor(sample)\n",
    "        \n",
    "        target = self.accent_id_dict[extract_num(self._datafiles[index])]\n",
    "\n",
    "        s_id = file_idx\n",
    "\n",
    "        transcript_path = f'{self.transcripts_path}{file_idx.split(\"_\")[-1]}.txt'\n",
    "        transcript = self.parse_transcript(transcript_path)\n",
    "\n",
    "        embedding = torch.load(f'{self.embeddings_path}{s_id}')\n",
    "\n",
    "        if self.ivectors_path is None:\n",
    "            return torch.FloatTensor(sample), target, embedding, transcript\n",
    "        else:\n",
    "            with open(os.path.join(self.ivectors_path, self._datafiles[index])) as f:\n",
    "                ivect = json.load(f)\n",
    "            return torch.FloatTensor(sample), target, transcript, embedding, torch.FloatTensor(ivect)\n",
    "        \n",
    "    def parse_transcript(self, transcript_path):\n",
    "        with open(transcript_path, 'r', encoding='utf8') as transcript_file:\n",
    "            transcript = transcript_file.read().replace('\\n', '')\n",
    "        transcript = list(filter(None, [self.labels_map.get(x) for x in list(transcript)]))\n",
    "        return transcript\n",
    "                      \n",
    "    def __len__(self):\n",
    "        return len(self._datafiles)\n",
    "    \n",
    "def collate_fn(batch_tot):\n",
    "    \"\"\"This function takes list of samples and assembles a batch. It is intended to used in PyTorch DataLoader.\"\"\"\n",
    "    batch = list(zip(*batch_tot))\n",
    "    ivect = None\n",
    "    \n",
    "    if len(batch) == 4:\n",
    "        input_, acc, emb, trs = batch\n",
    "    elif len(batch) == 5:\n",
    "        input_, acc, emb, trs, ivect = batch\n",
    "\n",
    "    input_lens = torch.tensor([len(r) for r in input_])\n",
    "    acc = torch.tensor(acc)\n",
    "    \n",
    "    input_ = nn.utils.rnn.pad_sequence(input_, batch_first=True)\n",
    "\n",
    "    target_lens = torch.tensor([len(t) for t in trs])\n",
    "\n",
    "    if ivect is not None:\n",
    "        ivect = nn.utils.rnn.pad_sequence(ivect, batch_first=True)\n",
    "        ivect = tile(ivect, 1, 10)\n",
    "        ivect = ivect[:, :input_.size(1), :]\n",
    "        input_ = torch.cat([input_, ivect], dim=2)\n",
    "    \n",
    "    __, idx = input_lens.sort(descending=True)\n",
    "    \n",
    "    targets = np.array(trs)[idx]\n",
    "    targets = torch.tensor([t for target in targets for t in target])\n",
    "    \n",
    "    input_ = input_[idx]\n",
    "    input_lens = input_lens[idx].int()\n",
    "    targets = targets.int()\n",
    "    target_lens = target_lens[idx].int()\n",
    "    acc = acc[idx].int()\n",
    "\n",
    "    emb = torch.cat(emb)\n",
    "    emb = emb[idx]\n",
    "    emb = emb.view(emb.size(0), 1, emb.size(1))\n",
    "    emb = tile(emb, 1, input_.size(1))\n",
    "\n",
    "    if emb.is_cuda:\n",
    "        input_ = input_.cuda()\n",
    "    input_ = torch.cat([input_, emb], dim=2)\n",
    "    \n",
    "    return input_, input_lens, targets, target_lens, acc\n",
    "\n",
    "class KaldiDeepspeechDataLoader(DataLoader):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Creates a data loader for SpeechDatasets.\n",
    "        \"\"\"\n",
    "        super(KaldiDeepspeechDataLoader, self).__init__(*args, **kwargs)\n",
    "        self.collate_fn = collate_fn\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_loader(test_manif):\n",
    "    test_dict, __ = make_accent_dict(test_manif)\n",
    "\n",
    "    test_dataset = KaldiDeepspeechDataset(data_path=param['test_kaldi'],\n",
    "                                  labels=param['labels'],\n",
    "                                  sample_ids=ids_list(test_manif), \n",
    "                                  transcripts_path=param['test_transcripts'],\n",
    "                                  embeddings_path=param['test_embeddings_100'],\n",
    "                                  accent_id_dict=test_dict,\n",
    "                                  ivectors_path=None)\n",
    "\n",
    "    test_loader = KaldiDeepspeechDataLoader(test_dataset, \n",
    "                                    shuffle=True, \n",
    "                                    num_workers=0,\n",
    "                                    batch_size=param['batch_size'])\n",
    "    return test_loader\n",
    "    \n",
    "    \n",
    "test_loaders = {k: get_test_loader(v) for k, v in test_manif.items()}\n",
    "\n",
    "# for data in test_loaders['native']:\n",
    "#     print(data)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AccentClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_size,\n",
    "                 num_classes,\n",
    "                 rnn_type,\n",
    "                 hidden_size,\n",
    "                 bn_size,\n",
    "                 DEBUG = False,):\n",
    "\n",
    "        super(AccentClassifier, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self._DEBUG = DEBUG\n",
    "\n",
    "        self.rnn = rnn_type(input_size, hidden_size, 2, \n",
    "                            bidirectional=True, \n",
    "                            batch_first=True)\n",
    "\n",
    "#         self.rnn = BatchRNN(input_size, \n",
    "#                             hidden_size,\n",
    "#                             rnn_type=rnn_type,bidirectional=True,\n",
    "#                             batch_norm=True)\n",
    "\n",
    "        self.bn = nn.Sequential(\n",
    "            nn.BatchNorm1d(hidden_size * 2),\n",
    "            nn.Linear(hidden_size * 2, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.Linear(1024, bn_size),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.BatchNorm1d(bn_size),\n",
    "            nn.Linear(bn_size, num_classes),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x, lens):\n",
    "        if self._DEBUG:\n",
    "            print('input x', x.size())\n",
    "\n",
    "        x = nn.utils.rnn.pack_padded_sequence(x, lens, batch_first=True)\n",
    "        x, __ = self.rnn(x)\n",
    "        x, lens = nn.utils.rnn.pad_packed_sequence(x, batch_first=True)\n",
    "\n",
    "        if self._DEBUG:\n",
    "            print('after rnn', x.size())\n",
    "#        \n",
    "#         x = x.view(x.size(0), x.size(1), 2, self.hidden_size)\n",
    "\n",
    "#         if self._DEBUG:\n",
    "#             print('after view', x.size())\n",
    "\n",
    "        x = x.mean(dim=1)\n",
    "\n",
    "        if self._DEBUG:\n",
    "            print('after mean', x.size())\n",
    "\n",
    "        x = self.bn(x)\n",
    "        bn = x\n",
    "\n",
    "        if self._DEBUG:\n",
    "            print('after bn', x.size())\n",
    "\n",
    "        x = self.fc(x)\n",
    "\n",
    "        if self._DEBUG:\n",
    "            print('after fc', x.size())\n",
    "\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        if self._DEBUG:\n",
    "            print('after softmax', x.size())\n",
    "        return x, bn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Head(nn.Module):\n",
    "    def __init__(self, \n",
    "                rnn_type=nn.LSTM, \n",
    "                labels=\"abc\", \n",
    "                rnn_hidden_size=768, \n",
    "                nb_layers=5, \n",
    "                bidirectional=True,\n",
    "                DEBUG=False):\n",
    "\n",
    "        super(Head, self).__init__()\n",
    "\n",
    "        # model metadata needed for serialization/deserialization\n",
    "        self._DEBUG = DEBUG\n",
    "        self._hidden_size = rnn_hidden_size\n",
    "        self._nb_layers = nb_layers\n",
    "        self._rnn_type = rnn_type\n",
    "        self._labels = labels\n",
    "        self._bidirectional = bidirectional\n",
    "\n",
    "        self.conv = MaskConv(nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=(41, 11), stride=(2, 2), padding=(20, 5)),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Hardtanh(0, 20, inplace=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=(21, 11), stride=(2, 1), padding=(10, 5)),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Hardtanh(0, 20, inplace=True)\n",
    "        ))\n",
    "\n",
    "        rnn_input_size = 1120\n",
    "\n",
    "        rnns = []\n",
    "        rnn = BatchRNN(input_size=rnn_input_size, hidden_size=rnn_hidden_size, rnn_type=rnn_type,\n",
    "                       bidirectional=bidirectional, batch_norm=False)\n",
    "        rnns.append(('0', rnn))\n",
    "        for x in range(nb_layers - 1):\n",
    "            rnn = BatchRNN(input_size=rnn_hidden_size, hidden_size=rnn_hidden_size, rnn_type=rnn_type,\n",
    "                           bidirectional=bidirectional)\n",
    "            rnns.append(('%d' % (x + 1), rnn))\n",
    "        self.rnns = nn.Sequential(OrderedDict(rnns))\n",
    "\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        if self._DEBUG:\n",
    "            print('')\n",
    "            print('#Â BEGIN HEADÂ #')\n",
    "            print('input', x.size())\n",
    "\n",
    "        lengths = lengths.cpu().int()\n",
    "        output_lengths = self.get_seq_lens(lengths)\n",
    "\n",
    "        x = x.view(x.size(0), 1, x.size(1), x.size(2))\n",
    "        x = x.transpose(2, 3)\n",
    "        if self._DEBUG:\n",
    "            print('after view transpose', x.size())\n",
    "\n",
    "        x, _ = self.conv(x, output_lengths)\n",
    "        if self._DEBUG:\n",
    "            print('after conv', x.size())\n",
    "\n",
    "        sizes = x.size()\n",
    "        x = x.view(sizes[0], sizes[1] * sizes[2], sizes[3])  # Collapse feature dimension\n",
    "        x = x.transpose(1, 2).transpose(0, 1).contiguous()  # TxNxH\n",
    "        if self._DEBUG:\n",
    "            print('after view transpose', x.size())\n",
    "\n",
    "        for rnn in self.rnns:\n",
    "            x = rnn(x, output_lengths)\n",
    "        if self._DEBUG:\n",
    "            print('after rnn', x.size())\n",
    "\n",
    "        self._DEBUG = False\n",
    "        return x, output_lengths\n",
    "\n",
    "    def get_seq_lens(self, input_length):\n",
    "        \"\"\"\n",
    "        Given a 1D Tensor or Variable containing integer sequence lengths, return a 1D tensor or variable\n",
    "        containing the size sequences that will be output by the network.\n",
    "        :param input_length: 1D Tensor\n",
    "        :return: 1D Tensor scaled by model\n",
    "        \"\"\"\n",
    "        seq_len = input_length\n",
    "        for m in self.conv.modules():\n",
    "            if type(m) == nn.modules.conv.Conv2d:\n",
    "                seq_len = ((seq_len + 2 * m.padding[1] - m.dilation[1] * (m.kernel_size[1] - 1) - 1) / m.stride[1] + 1)\n",
    "        return seq_len.int()\n",
    "\n",
    "class FC(nn.Module):\n",
    "    def __init__(self, \n",
    "                 rnn_hidden_size=768,\n",
    "                 labels='abc',\n",
    "                 DEBUG=False,):\n",
    "\n",
    "        super(FC, self).__init__()\n",
    "\n",
    "        self._DEBUG = DEBUG\n",
    "        self._labels = labels\n",
    "        num_classes = len(self._labels)\n",
    "\n",
    "        fully_connected = nn.Sequential(\n",
    "            nn.BatchNorm1d(rnn_hidden_size),\n",
    "            nn.Linear(rnn_hidden_size, num_classes, bias=False)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            SequenceWise(fully_connected),\n",
    "        )\n",
    "        self.inference_softmax = InferenceBatchSoftmax()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self._DEBUG:\n",
    "            print('')\n",
    "            print('# BEGIN FC #')\n",
    "            print('input', x.size())\n",
    "        x = self.fc(x)\n",
    "        if self._DEBUG:\n",
    "            print('after fc', x.size())\n",
    "\n",
    "        x = x.transpose(0, 1)\n",
    "        if self._DEBUG:\n",
    "            print('after transpose', x.size())\n",
    "        # identity in training mode, softmax in eval mode\n",
    "        x = self.inference_softmax(x)\n",
    "        if self._DEBUG:\n",
    "            print('after softmax', x.size())\n",
    "\n",
    "        x = x.transpose(0, 1)\n",
    "        if self._DEBUG:\n",
    "            print('after transpose', x.size())\n",
    "\n",
    "        self._DEBUG = False\n",
    "        return x\n",
    "\n",
    "\n",
    "class AccentClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_size,\n",
    "                 accents={},\n",
    "                 DEBUG=False,):\n",
    "\n",
    "        super(AccentClassifier, self).__init__()\n",
    "\n",
    "        num_classes = len(accents)\n",
    "        self._DEBUG = DEBUG\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.BatchNorm1d(input_size),\n",
    "            nn.Linear(input_size, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.Linear(1024, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Linear(256, num_classes),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):     \n",
    "        if self._DEBUG:\n",
    "            print('')\n",
    "            print('# BEGIN Acc #')\n",
    "            print('input', x.size())\n",
    "\n",
    "        x = x.mean(dim=0)\n",
    "\n",
    "        if self._DEBUG:\n",
    "            print('after mean', x.size())\n",
    "\n",
    "        x = self.fc(x)\n",
    "\n",
    "        if self._DEBUG:\n",
    "            print('after fc', x.size())\n",
    "\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        if self._DEBUG:\n",
    "            print('after softmax', x.size())\n",
    "\n",
    "        self._DEBUG = False\n",
    "        return x\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self, \n",
    "                rnn_type=nn.LSTM, \n",
    "                labels=\"abc\", \n",
    "                accents={},\n",
    "                rnn_hidden_size=768, \n",
    "                nb_layers=5, \n",
    "                audio_conf=None,\n",
    "                bidirectional=True,\n",
    "                DEBUG=False):\n",
    "\n",
    "        super(Network, self).__init__()\n",
    "\n",
    "        self.Head = Head(rnn_type=rnn_type, \n",
    "                        labels=labels, \n",
    "                        rnn_hidden_size=rnn_hidden_size, \n",
    "                        nb_layers=nb_layers, \n",
    "                        bidirectional=bidirectional,\n",
    "                        DEBUG=DEBUG)\n",
    "\n",
    "        self.FC = FC(rnn_hidden_size=rnn_hidden_size,\n",
    "                     labels=labels,\n",
    "                     DEBUG=DEBUG,)\n",
    "\n",
    "        self.Acc = AccentClassifier(input_size=800,\n",
    "                                  accents=accents,\n",
    "                                  DEBUG=DEBUG)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        x, out_len = self.Head(x, lengths)\n",
    "        x_fc = self.FC(x)\n",
    "        x_acc = self.Acc(x)\n",
    "        return x_fc, x_acc, out_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute 'DeepSpeech' on <module '__main__'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-257afd3fe162>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_TO_LOAD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module)\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_fd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(f, map_location, pickle_module)\u001b[0m\n\u001b[1;32m    540\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[0mdeserialized_storage_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can't get attribute 'DeepSpeech' on <module '__main__'>"
     ]
    }
   ],
   "source": [
    "model = torch.load(MODEL_TO_LOAD)\n",
    "\n",
    "if param['cuda']:\n",
    "    model.cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=param['lr'][0])\n",
    "\n",
    "criterion = CTCLoss()\n",
    "\n",
    "decoder = BeamCTCDecoder(param['labels'], lm_path=param['lm_path'],\n",
    "                        alpha=0.8, beta=1.,\n",
    "                        cutoff_top_n=40, cutoff_prob=1.0,\n",
    "                        beam_width=100, num_processes=param['num_worker'])\n",
    "\n",
    "target_decoder = GreedyDecoder(param['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_wer(targets, targets_len, out, output_len):\n",
    "    split_targets = []\n",
    "    offset = 0\n",
    "    for size in targets_len:\n",
    "        split_targets.append(targets[offset:offset + size])\n",
    "        offset += size\n",
    "        \n",
    "    decoded_output, _ = decoder.decode(out.data.transpose(0,1), output_len)\n",
    "    target_strings = target_decoder.convert_to_strings(split_targets)\n",
    "    \n",
    "    if False:\n",
    "        print('targets', targets)\n",
    "        print('split_targets', split_targets)\n",
    "        print('out', out)\n",
    "        print('output_len', output_len)\n",
    "        print('decoded', decoded_output)\n",
    "        print('target', target_strings)\n",
    "    \n",
    "    wer, cer = 0, 0\n",
    "    for x in range(len(target_strings)):\n",
    "        transcript, reference = decoded_output[x][0], target_strings[x][0]\n",
    "        wer += decoder.wer(transcript, reference) / float(len(reference.split()))\n",
    "        #cer += decoder.cer(transcript, reference) / float(len(reference))\n",
    "    wer /= len(target_strings)\n",
    "    return wer * 100\n",
    "\n",
    "def check_acc(targets, out):\n",
    "    out_arg = np.argmax(out, axis=1)\n",
    "    diff = torch.eq(out_arg.int(), targets)\n",
    "    acc = torch.sum(diff).float()\n",
    "    return acc / len(targets) * 100\n",
    "\n",
    "def get_loss(inputs, inputs_len, targets, targets_len, target_accents, mix):\n",
    "    \n",
    "    inputs = inputs.cuda()\n",
    "    inputs_len = inputs_len.cuda()\n",
    "    targets = targets.cuda()\n",
    "    targets_len = targets_len.cuda()\n",
    "\n",
    "    # Forward pass\n",
    "    out_fc, out_acc, output_len = model(inputs, inputs_len)\n",
    "\n",
    "    out_fc = out_fc.cpu()\n",
    "    targets = targets.cpu()\n",
    "    targets_len = targets_len.cpu()\n",
    "    out_acc = out_acc.cpu()\n",
    "\n",
    "    if False:\n",
    "        print('## Outputs train')\n",
    "        print('out', out.size())\n",
    "        print('targets', targets.size())\n",
    "        print('output_len', output_len.size())\n",
    "        print('targets_len', targets_len.size())\n",
    "\n",
    "    loss_fc = crit_fc(out_fc, targets, output_len, targets_len)\n",
    "    loss_acc = crit_acc(out_acc, target_accents.long()) * 3000\n",
    "    loss = mix * loss_fc + (1 - mix) * loss_acc\n",
    "    \n",
    "    total_loss = (loss, loss_fc, loss_acc)\n",
    "    return total_loss, out_fc, out_acc, output_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_loader):\n",
    "    DEBUG=False\n",
    "    model.eval()\n",
    "    epoch_val_losses = []\n",
    "    epoch_wer = []\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(test_loader, total=len(test_loader)): ## ## \n",
    "            inputs, inputs_len, targets, targets_len, target_accents = data\n",
    "\n",
    "            inputs = inputs.cuda()\n",
    "            inputs_len = inputs_len.cuda()\n",
    "            targets = targets.cuda()\n",
    "            targets_len = targets_len.cuda()\n",
    "            target_accents = target_accents.cuda()\n",
    "\n",
    "            out, output_len = model(inputs, inputs_len)\n",
    "\n",
    "            out = out.cpu()\n",
    "            targets = targets.cpu()\n",
    "            targets_len = targets_len.cpu()\n",
    "\n",
    "            if False:\n",
    "                print('## Outputs test')\n",
    "                print('out', out)\n",
    "                print('targets', targets)\n",
    "                print('output_len', output_len)\n",
    "                print('targets_len', targets_len)\n",
    "\n",
    "            val_loss = criterion(out, targets, output_len, targets_len)\n",
    "\n",
    "            if DEBUG:\n",
    "                print('val loss', val_loss)\n",
    "\n",
    "            epoch_val_losses.append(val_loss)\n",
    "\n",
    "            wer = check_wer(targets, targets_len, out, output_len)\n",
    "            epoch_wer.append(wer)\n",
    "\n",
    "    epoch_val_loss = sum(epoch_val_losses) / len(epoch_val_losses) ##\n",
    "    epoch_wer = sum(epoch_wer) / len(epoch_wer)\n",
    "    return epoch_wer, epoch_val_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d06dc888ce9140fbb8c7e7fd1ebea042",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "input.size(-1) must be equal to input_size. Expected 320, got 1120",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-2db4f999d604>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-51-2db4f999d604>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-50-b49153023d1d>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(test_loader)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mtarget_accents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_accents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-47-6781cc9e2b1c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, lengths)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m         \u001b[0mx_fc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mx_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAcc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-47-6781cc9e2b1c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, lengths)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mrnn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_DEBUG\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after rnn'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/deepspeech.pytorch/models/modules.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, output_lengths)\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_packed_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbidirectional\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0mflat_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         func = self._backend.RNN(\n\u001b[1;32m    180\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    128\u001b[0m             raise RuntimeError(\n\u001b[1;32m    129\u001b[0m                 'input.size(-1) must be equal to input_size. Expected {}, got {}'.format(\n\u001b[0;32m--> 130\u001b[0;31m                     self.input_size, input.size(-1)))\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_input_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 320, got 1120"
     ]
    }
   ],
   "source": [
    "results = {k: test(v) for k, v in test_loaders.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, (wer, acc) in results.items():\n",
    "    print(f'{k:>6}: {wer:.2f} wer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "native: 54.78 wer\n",
      "   lnn: 70.38 wer\n"
     ]
    }
   ],
   "source": [
    "# vac05\n",
    "for k, (wer, acc) in results.items():\n",
    "    print(f'{k:>6}: {wer:.2f} wer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
