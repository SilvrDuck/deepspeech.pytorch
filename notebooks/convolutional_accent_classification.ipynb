{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Â Concatenative accent classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "DEV = True\n",
    "EPOCHS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoreloads\n",
    "%reload_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport parameters\n",
    "\n",
    "# Allows to load modules from parent directory\n",
    "from time import time\n",
    "import inspect, sys\n",
    "from os.path import dirname, abspath\n",
    "sys.path.append(dirname(dirname(abspath(inspect.getfile(inspect.currentframe())))))\n",
    "\n",
    "from pathlib import Path\n",
    "from os import makedirs\n",
    "\n",
    "#from models.accent_classifier import AccentClassifier\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from torch.nn.modules import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from data.data_loader import create_binarizer, get_accents_counts\n",
    "from data.data_loader import SpectrogramAccentDataset, BucketingSampler, AudioDataLoader\n",
    "from utils import count_parameters, Timer\n",
    "\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = []\n",
    "import math\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from models.modules import MaskConv, SequenceWise, BatchRNN, InferenceBatchSoftmax, \\\n",
    "                    supported_rnns, supported_rnns_inv\n",
    "\n",
    "class AccentClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "                 labels,\n",
    "                 audio_conf={}, \n",
    "                 rnn_hidden_size=800,\n",
    "                 rnn_type=nn.GRU,\n",
    "                 DEBUG = False, \n",
    "                 clip=125):\n",
    "        \n",
    "        super(AccentClassifier, self).__init__()\n",
    "        \n",
    "        self._DEBUG = DEBUG\n",
    "\n",
    "        # metadata\n",
    "        self._audio_conf = audio_conf\n",
    "        self._labels = labels\n",
    "        self._num_classes = len(labels)\n",
    "        self._clip = clip\n",
    "        \n",
    "        sample_rate = self._audio_conf.get(\"sample_rate\", 16000)\n",
    "        window_size = self._audio_conf.get(\"window_size\", 0.02)\n",
    "\n",
    "        self.conv = MaskConv(nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Hardtanh(0, 20, inplace=True),\n",
    "            nn.MaxPool2d(4),\n",
    "            nn.Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Hardtanh(0, 20, inplace=True),\n",
    "            nn.MaxPool2d(4)\n",
    "        ))\n",
    "\n",
    "        # Based on above convolutions and spectrogram size using conv formula (W - F + 2P)/ S+1\n",
    "        conv_output_size = int(math.floor((sample_rate * window_size) / 2) + 1)\n",
    "        conv_output_size = int(math.floor(conv_output_size + 2 * 20 - 41) / 2 + 1)\n",
    "        conv_output_size = int(math.floor(conv_output_size + 2 * 10 - 21) / 2 + 1)\n",
    "        conv_output_size = int(math.floor((conv_output_size + 1 * (8 - 1) - 1)) / 8 + 1)\n",
    "        conv_output_size *= 32\n",
    "        conv_output_size *= self._clip\n",
    "        conv_output_size = 40000 # TODO\n",
    "\n",
    "        #self.rnn = rnn_type(conv_output_size, conv_output_size, 1)\n",
    "        #self.rnn = BatchRNN(input_size=conv_output_size, \n",
    "        #                    hidden_size=conv_output_size, \n",
    "        #                    rnn_type=rnn_type, \n",
    "        #                    bidirectional=True, \n",
    "        #                    batch_norm=False)\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.BatchNorm1d(conv_output_size),\n",
    "            nn.Linear(conv_output_size, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.Linear(1024, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        #self.fc = SequenceWise(fully_co)\n",
    "        self.softmax = nn.LogSoftmax(dim=-1)\n",
    "        #self.inference_softmax = InferenceBatchSoftmax()\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        lengths = lengths.cpu().int()\n",
    "        output_lengths = self.get_seq_lens(lengths)\n",
    "        if self._DEBUG:\n",
    "            print('input', x.size())\n",
    "        x, _ = self.conv(x, output_lengths)\n",
    "        if self._DEBUG:\n",
    "            print('afetr conv', x.size())\n",
    "        #sizes = x.size()\n",
    "        #x = x.view(sizes[0], sizes[1] * sizes[2] * sizes[3])  # Collapse feature dimension\n",
    "        #x = x.transpose(1, 2).transpose(0, 1).contiguous()  # TxNxH\n",
    "        #print('bef', x.size())\n",
    "        #x = x.view(x.size(0), -1)\n",
    "        #if DEBUG:\n",
    "            #print('after view', x.size())\n",
    "        #x = torch.sum(x, dim=2)\n",
    "        #if DEBUG:\n",
    "           # print('after sum', x.size())\n",
    "        #x = x.transpose(0, 1).contiguous()\n",
    "        \n",
    "        \n",
    "        x = x.view(x.size(0), x.size(1) * x.size(2), x.size(3))\n",
    "        x = x.transpose(1, 2)\n",
    "        #x = x.transpose(0, 1)\n",
    "        \n",
    "        if self._DEBUG:\n",
    "            print('after view trans', x.size())\n",
    "        \n",
    "        #x, __ = self.rnn(x)\n",
    "        samples.append(x.size(1))\n",
    "        if x.size(1) >= self._clip:\n",
    "            x = x[:, :self._clip, :].contiguous()\n",
    "        else:\n",
    "            z = torch.zeros(torch.Size((x.size(0), self._clip - x.size(1), x.size(2))))\n",
    "            z = z.cuda() if x.is_cuda else z\n",
    "            x = torch.cat((x, z), 1)\n",
    "        \n",
    "        #if self._DEBUG:\n",
    "        #    print('after gru', x.size())\n",
    "        \n",
    "        #x = x.transpose(0, 1)\n",
    "        #x = x[:, -1, :]\n",
    "        \n",
    "        if self._DEBUG:\n",
    "            print('after clip', x.size())\n",
    "            \n",
    "        x = x.view(x.size(0), x.size(1) * x.size(2))\n",
    "        if self._DEBUG:\n",
    "            print('after view', x.size())\n",
    "\n",
    "        x = self.fc(x)\n",
    "\n",
    "        if self._DEBUG:\n",
    "            print('after fully co', x.size())\n",
    "        #x = x.transpose(0, 1)\n",
    "        if self._DEBUG:\n",
    "            print('after transpose', x.size())\n",
    "        # identity in training mode, softmax in eval mode\n",
    "        #x = self.inference_softmax(x)\n",
    "        #x = self.softmax(x)\n",
    "        if self._DEBUG:\n",
    "            print('after softmax', x.size())\n",
    "        #x = x.transpose(0, 1)\n",
    "        if self._DEBUG:\n",
    "            print('output', x.size())\n",
    "            print('###########')\n",
    "        return x\n",
    "    \n",
    "    def get_seq_lens(self, input_length):\n",
    "        \"\"\"\n",
    "        Given a 1D Tensor or Variable containing integer sequence lengths, return a 1D tensor or variable\n",
    "        containing the size sequences that will be output by the network.\n",
    "        :param input_length: 1D Tensor\n",
    "        :return: 1D Tensor scaled by model\n",
    "        \"\"\"\n",
    "        seq_len = input_length\n",
    "        for m in self.conv.modules():\n",
    "            if type(m) == nn.modules.conv.Conv2d:\n",
    "                seq_len = ((seq_len + 2 * m.padding[1] - m.dilation[1] * (m.kernel_size[1] - 1) - 1) / m.stride[1] + 1)\n",
    "        return seq_len.int()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure experiments by directly changing the values in parameters.py\n",
    "param = parameters.get_parameters(dev=DEV, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def now():\n",
    "    localtime   = time.localtime()\n",
    "    timeString  = time.strftime(\"%Y-%m-%d_%Hh%M:%S\", localtime)\n",
    "    return timeString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorboard\n",
    "exp_name = f'__tmp__{now()}'\n",
    "tb_path = Path(param['tensorboard_dir']) / exp_name\n",
    "makedirs(tb_path, exist_ok=True)\n",
    "tb_writer = SummaryWriter(tb_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data):\n",
    "    inputs, targets, input_percentages, target_sizes, target_accents = data\n",
    "    if len(target_accents[0]) > 1:\n",
    "        target_accents = np.argmax(target_accents, axis=1)\n",
    "    #else:\n",
    "        #target_accents = target_accents.view(target_accents.size(0))\n",
    "        \n",
    "    target_accents = target_accents.float()\n",
    "        \n",
    "    if param['cuda']:\n",
    "        inputs = inputs.cuda()\n",
    "        target_accents = target_accents.cuda()\n",
    "    \n",
    "    input_sizes = input_percentages.mul_(int(inputs.size(3))).int()       \n",
    "    return inputs, target_accents, input_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_conf = {'sample_rate': param['sample_rate'],\n",
    "                'window_size': param['window_size'],\n",
    "                'window_stride': param['window_stride'],\n",
    "                'window': param['window'],\n",
    "                'noise_dir': param['noise_dir'],\n",
    "                'noise_prob': param['noise_prob'],\n",
    "                'noise_levels': (param['noise_min'], param['noise_max'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "accent_binarizer = create_binarizer(param['train_manifest'])\n",
    "labels = accent_binarizer.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SpectrogramAccentDataset(audio_conf=audio_conf, \n",
    "                                        manifest_filepath=param['train_manifest'], \n",
    "                                        labels=labels,\n",
    "                                        normalize=True, \n",
    "                                        augment=param['augment'], \n",
    "                                        accent_binarizer=accent_binarizer,\n",
    "                                        kaldi=False)\n",
    "\n",
    "train_sampler = BucketingSampler(train_dataset, batch_size=param['batch_size'])\n",
    "\n",
    "train_loader = AudioDataLoader(train_dataset,\n",
    "                                num_workers=param['num_worker'], \n",
    "                                batch_sampler=train_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = SpectrogramAccentDataset(audio_conf=audio_conf, \n",
    "                                        manifest_filepath=param['test_manifest'], \n",
    "                                        labels=labels,\n",
    "                                        normalize=True, \n",
    "                                        augment=False, \n",
    "                                        accent_binarizer=accent_binarizer,\n",
    "                                        kaldi=False)\n",
    "\n",
    "test_loader = AudioDataLoader(test_dataset,\n",
    "                                num_workers=param['num_worker'], \n",
    "                                batch_size=param['batch_size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_counts = get_accents_counts(param['train_manifest'])\n",
    "# class_counts = [train_counts[c] / max(train_counts.values()) for c in accent_binarizer.classes_]\n",
    "# weights = 1 / torch.tensor(class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weights = torch.tensor([1. for __ in weights])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AccentClassifier(\n",
      "  (conv): MaskConv(\n",
      "    (seq_module): Sequential(\n",
      "      (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): Hardtanh(min_val=0, max_val=20, inplace)\n",
      "      (3): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "      (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): Hardtanh(min_val=0, max_val=20, inplace)\n",
      "      (7): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): BatchNorm1d(40000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (1): Linear(in_features=40000, out_features=1024, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): Linear(in_features=1024, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (8): Sigmoid()\n",
      "  )\n",
      "  (softmax): LogSoftmax()\n",
      ")\n",
      "Model parameters counts: 41315937\n"
     ]
    }
   ],
   "source": [
    "model = AccentClassifier(labels=labels, \n",
    "                         audio_conf=audio_conf, \n",
    "                         rnn_hidden_size=param['rnn_hidden_size'],  \n",
    "                         rnn_type=param['rnn_type'], \n",
    "                         DEBUG=DEBUG)\n",
    "if param['cuda']:\n",
    "    model.cuda()\n",
    "    #weights = weights.cuda()\n",
    "    \n",
    "if len(labels) == 2:\n",
    "    criterion = nn.BCELoss()\n",
    "else:\n",
    "    criterion = CrossEntropyLoss()\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=param['lr'][0])\n",
    "\n",
    "print(model)\n",
    "print('Model parameters counts:', count_parameters(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## EPOCH 1 ##\n",
      "Training:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b89f91145da04b62be14ab4532de083c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 average loss: 0.640\n",
      "Testing:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc5d803766ee471fb6a0a92b686ec4b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=30), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accent classification accuracy: 50.00%\n",
      "Average validation loss: 0.738\n",
      "New best model found.\n",
      "\n",
      "## EPOCH 2 ##\n",
      "Training:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ca2528221344b5da2044066a187862d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2 average loss: 0.648\n",
      "Testing:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "946b4588e3a74ffe8f1d2a29d358761e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=30), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accent classification accuracy: 50.00%\n",
      "Average validation loss: 0.701\n",
      "\n",
      "## EPOCH 3 ##\n",
      "Training:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8de1236dd8834bbda683a82e21cfa2df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3 average loss: 0.637\n",
      "Testing:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1869330417de4ce7915beb6ef427adc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=30), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accent classification accuracy: 50.00%\n",
      "Average validation loss: 0.683\n",
      "\n",
      "## EPOCH 4 ##\n",
      "Training:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f02a70d415374d6bbf6d02332ac01c9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4 average loss: 0.622\n",
      "Testing:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a32fb4c7ba742aa9e61d7ea0dcd2792",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=30), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accent classification accuracy: 50.00%\n",
      "Average validation loss: 0.712\n"
     ]
    }
   ],
   "source": [
    "SILENT = True\n",
    "    \n",
    "t = Timer()\n",
    "\n",
    "best_model = None\n",
    "prev_acc = 0\n",
    "## Train\n",
    "for epoch in range(1, param['epochs'] + 1):\n",
    "    print(f'\\n## EPOCH {epoch} ##')\n",
    "    print(f'Training:')\n",
    "    model.train()\n",
    "    \n",
    "    # train\n",
    "    epoch_losses = []\n",
    "    t.add(f'EPOCH {epoch}')\n",
    "    for i, data in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "        t.add('Start loop')\n",
    "        inputs, target_accents, input_sizes = process_data(data)\n",
    "\n",
    "        # Forward pass\n",
    "        t.add('Process data')\n",
    "        out = model(inputs, input_sizes)\n",
    "        t.add('Forward')\n",
    "\n",
    "        loss = criterion(out, target_accents) #prbly fix that TODODODODO\n",
    "        t.add('Criterion')\n",
    "        epoch_losses.append(loss)\n",
    "        \n",
    "        if not SILENT:\n",
    "            print(f'Iteration {i+1}/{len(train_loader):<4}loss: {loss:0.3f}')\n",
    "        \n",
    "        # Gradient\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        t.add('Backward')\n",
    "        \n",
    "        #clip_grad_norm_(model.parameters(), param['max_norm'])\n",
    "        optimizer.step()\n",
    "        t.add('End loop')\n",
    "    t.add(f'END EPOCH {epoch}')\n",
    "    t.reset_time()\n",
    "    \n",
    "    epoch_loss = sum(epoch_losses) / len(train_loader)\n",
    "    tb_writer.add_scalar('stats/train_loss', epoch_loss, epoch)\n",
    "    print(f'Epoch {epoch} average loss: {epoch_loss:0.3f}')\n",
    "        \n",
    "    # validate\n",
    "    print(f'Testing:')\n",
    "    model.eval()\n",
    "    acc = 0\n",
    "    tot = 0\n",
    "    with torch.no_grad():\n",
    "        epoch_val_losses = []\n",
    "        for data in tqdm(test_loader, total=len(test_loader)):\n",
    "            inputs, target_accents, input_sizes = process_data(data) \n",
    "            out = model(inputs, input_sizes)\n",
    "            \n",
    "            val_loss = criterion(out, target_accents)\n",
    "            epoch_val_losses.append(val_loss)\n",
    "            \n",
    "            for x in range(len(target_accents)):\n",
    "                accent_out = round(out[x].item())\n",
    "                accent_target = target_accents[x]\n",
    "\n",
    "                if accent_out == accent_target.item():\n",
    "                    acc += 1\n",
    "                tot += 1\n",
    "\n",
    "        acc = acc / tot * 100\n",
    "        epoch_val_loss = sum(epoch_val_losses) / len(test_loader)\n",
    "        \n",
    "    tb_writer.add_scalar('stats/accuracy', acc, epoch)\n",
    "    print(f'Accent classification accuracy: {acc:0.2f}%')\n",
    "    \n",
    "    tb_writer.add_scalar('stats/val_loss', epoch_val_loss, epoch)\n",
    "    print(f'Average validation loss: {val_loss:0.3f}')\n",
    "    \n",
    "    if acc > prev_acc:\n",
    "        print('New best model found.')\n",
    "        best_model = model\n",
    "        prev_acc = acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    np.set_printoptions(precision=2)\n",
    "    plt.figure()\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88b91c76f83d4603b015cd1d015fabb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=30), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "loader = test_loader\n",
    "\n",
    "y_true, y_pred = [], []\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(loader, total=len(loader)):\n",
    "        inputs, target_accents, input_sizes = process_data(data) \n",
    "        out = best_model(inputs, input_sizes)\n",
    "\n",
    "        for x in range(len(target_accents)):\n",
    "            y_true.append(target_accents[x])\n",
    "            y_pred.append(round(out[x].item()))\n",
    "            \n",
    "y_true_labels = [labels[int(i)] for i in y_true]\n",
    "y_pred_labels = [labels[i] for i in y_pred]\n",
    "\n",
    "cnf_mat = confusion_matrix(y_true_labels, y_pred_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(cnf_mat, classes=labels, normalize=False, title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True counts\n",
      "us         625\n",
      "england    625\n",
      "dtype: int64\n",
      "\n",
      "Pred counts\n",
      "england    1220\n",
      "us           30\n",
      "dtype: int64\n",
      "\n",
      "Deviation from center: 95.20%\n"
     ]
    }
   ],
   "source": [
    "print('True counts')\n",
    "print(pd.Series(y_true).value_counts())\n",
    "print()\n",
    "print('Pred counts')\n",
    "pred_cnts = pd.Series(y_pred).value_counts()\n",
    "print(pred_cnts)\n",
    "print()\n",
    "print(f'Deviation from center: {abs(0.5 - pred_cnts[0]/len(y_pred))*200:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "    england       0.50      0.98      0.66       625\n",
      "         us       0.53      0.03      0.05       625\n",
      "\n",
      "avg / total       0.52      0.50      0.36      1250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timer exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Event</th>\n",
       "      <th>Relative</th>\n",
       "      <th>Absolute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Start</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EPOCH 1</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>0.000436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Start loop</td>\n",
       "      <td>1.494065</td>\n",
       "      <td>1.494501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Forward</td>\n",
       "      <td>0.075975</td>\n",
       "      <td>1.570476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Criterion</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>1.570807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Backward</td>\n",
       "      <td>0.002446</td>\n",
       "      <td>1.573253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>End loop</td>\n",
       "      <td>0.134512</td>\n",
       "      <td>1.707765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Start loop</td>\n",
       "      <td>0.003862</td>\n",
       "      <td>1.711627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Forward</td>\n",
       "      <td>0.065375</td>\n",
       "      <td>1.777002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Criterion</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>1.777082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Event  Relative  Absolute\n",
       "0       Start  0.000000  0.000000\n",
       "1     EPOCH 1  0.000436  0.000436\n",
       "2  Start loop  1.494065  1.494501\n",
       "3     Forward  0.075975  1.570476\n",
       "4   Criterion  0.000332  1.570807\n",
       "5    Backward  0.002446  1.573253\n",
       "6    End loop  0.134512  1.707765\n",
       "7  Start loop  0.003862  1.711627\n",
       "8     Forward  0.065375  1.777002\n",
       "9   Criterion  0.000079  1.777082"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events = pd.DataFrame(t.events)[['Event', 'Relative', 'Absolute']]\n",
    "events.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Event</th>\n",
       "      <th>Relative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Backward</td>\n",
       "      <td>11.760916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Criterion</td>\n",
       "      <td>0.716652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>END EPOCH 1</td>\n",
       "      <td>0.003843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>END EPOCH 10</td>\n",
       "      <td>0.003312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>END EPOCH 2</td>\n",
       "      <td>0.003597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>END EPOCH 3</td>\n",
       "      <td>0.003425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>END EPOCH 4</td>\n",
       "      <td>0.003970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>END EPOCH 5</td>\n",
       "      <td>0.003595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>END EPOCH 6</td>\n",
       "      <td>0.002521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>END EPOCH 7</td>\n",
       "      <td>0.003401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>END EPOCH 8</td>\n",
       "      <td>0.003288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>END EPOCH 9</td>\n",
       "      <td>0.003376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>EPOCH 1</td>\n",
       "      <td>0.000436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>EPOCH 10</td>\n",
       "      <td>4.070034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>EPOCH 2</td>\n",
       "      <td>3.705642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>EPOCH 3</td>\n",
       "      <td>3.973263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>EPOCH 4</td>\n",
       "      <td>4.207866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>EPOCH 5</td>\n",
       "      <td>4.076436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>EPOCH 6</td>\n",
       "      <td>4.139190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>EPOCH 7</td>\n",
       "      <td>4.057251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>EPOCH 8</td>\n",
       "      <td>4.044169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>EPOCH 9</td>\n",
       "      <td>4.071436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>End loop</td>\n",
       "      <td>1215.725277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Forward</td>\n",
       "      <td>630.452336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Start</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Start loop</td>\n",
       "      <td>13338.061702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Timer reset</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Event      Relative\n",
       "0       Backward     11.760916\n",
       "1      Criterion      0.716652\n",
       "2    END EPOCH 1      0.003843\n",
       "3   END EPOCH 10      0.003312\n",
       "4    END EPOCH 2      0.003597\n",
       "5    END EPOCH 3      0.003425\n",
       "6    END EPOCH 4      0.003970\n",
       "7    END EPOCH 5      0.003595\n",
       "8    END EPOCH 6      0.002521\n",
       "9    END EPOCH 7      0.003401\n",
       "10   END EPOCH 8      0.003288\n",
       "11   END EPOCH 9      0.003376\n",
       "12       EPOCH 1      0.000436\n",
       "13      EPOCH 10      4.070034\n",
       "14       EPOCH 2      3.705642\n",
       "15       EPOCH 3      3.973263\n",
       "16       EPOCH 4      4.207866\n",
       "17       EPOCH 5      4.076436\n",
       "18       EPOCH 6      4.139190\n",
       "19       EPOCH 7      4.057251\n",
       "20       EPOCH 8      4.044169\n",
       "21       EPOCH 9      4.071436\n",
       "22      End loop   1215.725277\n",
       "23       Forward    630.452336\n",
       "24         Start      0.000000\n",
       "25    Start loop  13338.061702\n",
       "26   Timer reset      0.000000"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = events.groupby('Event').sum().reset_index()[['Event', 'Relative']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10dee29c51944bbeaa4896779e2a1f38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=50031), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "df = None\n",
    "for i, row in tqdm(events.iterrows(), total=len(events)):\n",
    "    if ('EPOCH' in row.Event) and ('END' not in row.Event):\n",
    "        if df is not None:\n",
    "            dfs.append(pd.DataFrame(df))\n",
    "        df = []\n",
    "    if df is not None:\n",
    "        df.append(row)\n",
    "else:\n",
    "    dfs.append(pd.DataFrame(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_sum = []\n",
    "for df in dfs:\n",
    "    df = df.groupby('Event').sum().reset_index()\n",
    "    epoch = df[df['Event'].apply(lambda e: ('EPOCH' in e) and ('END' not in e))].Event.iloc[0].split()[1]\n",
    "    df = df[['Event', 'Relative']]\n",
    "    df['epoch'] = epoch\n",
    "    df = df[df['Event'].apply(lambda e: ('EPOCH' not in e) and ('reset' not in e))]\n",
    "    dfs_sum.append(df)\n",
    "df_sum = pd.concat(dfs_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Event</th>\n",
       "      <th>Relative</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Backward</td>\n",
       "      <td>1.121399</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Criterion</td>\n",
       "      <td>0.068291</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>End loop</td>\n",
       "      <td>121.760889</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Forward</td>\n",
       "      <td>60.482495</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Start loop</td>\n",
       "      <td>195.474357</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Event    Relative epoch\n",
       "0    Backward    1.121399     1\n",
       "1   Criterion    0.068291     1\n",
       "4    End loop  121.760889     1\n",
       "5     Forward   60.482495     1\n",
       "6  Start loop  195.474357     1"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sum[df_sum['epoch'] == '1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Event</th>\n",
       "      <th>Relative</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Backward</td>\n",
       "      <td>1.121399</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Backward</td>\n",
       "      <td>1.168464</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Backward</td>\n",
       "      <td>1.174321</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Backward</td>\n",
       "      <td>1.165048</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Backward</td>\n",
       "      <td>1.181437</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Backward</td>\n",
       "      <td>1.186759</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Backward</td>\n",
       "      <td>1.201952</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Backward</td>\n",
       "      <td>1.186212</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Backward</td>\n",
       "      <td>1.181523</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Backward</td>\n",
       "      <td>1.193802</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Event  Relative epoch\n",
       "0  Backward  1.121399     1\n",
       "0  Backward  1.168464     2\n",
       "0  Backward  1.174321     3\n",
       "0  Backward  1.165048     4\n",
       "0  Backward  1.181437     5\n",
       "0  Backward  1.186759     6\n",
       "0  Backward  1.201952     7\n",
       "0  Backward  1.186212     8\n",
       "0  Backward  1.181523     9\n",
       "0  Backward  1.193802    10"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def df_for(for_, df=df_sum):\n",
    "    return df[df['Event'].apply(lambda e: for_ in e)]\n",
    "df_for('Backward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Event</th>\n",
       "      <th>Relative</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>End loop</td>\n",
       "      <td>121.760889</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>End loop</td>\n",
       "      <td>121.604301</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>End loop</td>\n",
       "      <td>121.476732</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>End loop</td>\n",
       "      <td>121.805236</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>End loop</td>\n",
       "      <td>121.570528</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>End loop</td>\n",
       "      <td>121.599942</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>End loop</td>\n",
       "      <td>120.969714</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>End loop</td>\n",
       "      <td>121.313114</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>End loop</td>\n",
       "      <td>122.150156</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>End loop</td>\n",
       "      <td>121.474665</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Event    Relative epoch\n",
       "4  End loop  121.760889     1\n",
       "4  End loop  121.604301     2\n",
       "4  End loop  121.476732     3\n",
       "4  End loop  121.805236     4\n",
       "4  End loop  121.570528     5\n",
       "4  End loop  121.599942     6\n",
       "4  End loop  120.969714     7\n",
       "4  End loop  121.313114     8\n",
       "4  End loop  122.150156     9\n",
       "4  End loop  121.474665    10"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_for('End')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Event</th>\n",
       "      <th>Relative</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Forward</td>\n",
       "      <td>60.482495</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Forward</td>\n",
       "      <td>61.910983</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Forward</td>\n",
       "      <td>63.400217</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Forward</td>\n",
       "      <td>63.693729</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Forward</td>\n",
       "      <td>63.774350</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Forward</td>\n",
       "      <td>63.623479</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Forward</td>\n",
       "      <td>63.128641</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Forward</td>\n",
       "      <td>63.479438</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Forward</td>\n",
       "      <td>63.645172</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Forward</td>\n",
       "      <td>63.313831</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Event   Relative epoch\n",
       "5  Forward  60.482495     1\n",
       "5  Forward  61.910983     2\n",
       "5  Forward  63.400217     3\n",
       "5  Forward  63.693729     4\n",
       "5  Forward  63.774350     5\n",
       "5  Forward  63.623479     6\n",
       "5  Forward  63.128641     7\n",
       "5  Forward  63.479438     8\n",
       "5  Forward  63.645172     9\n",
       "5  Forward  63.313831    10"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_for('Forward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Event</th>\n",
       "      <th>Relative</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Start loop</td>\n",
       "      <td>195.474357</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Start loop</td>\n",
       "      <td>1030.027789</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Start loop</td>\n",
       "      <td>1365.159696</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Start loop</td>\n",
       "      <td>1501.683723</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Start loop</td>\n",
       "      <td>1531.223236</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Start loop</td>\n",
       "      <td>1538.300006</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Start loop</td>\n",
       "      <td>1522.411878</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Start loop</td>\n",
       "      <td>1557.755526</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Start loop</td>\n",
       "      <td>1554.391542</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Start loop</td>\n",
       "      <td>1541.633949</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Event     Relative epoch\n",
       "6  Start loop   195.474357     1\n",
       "6  Start loop  1030.027789     2\n",
       "6  Start loop  1365.159696     3\n",
       "6  Start loop  1501.683723     4\n",
       "6  Start loop  1531.223236     5\n",
       "6  Start loop  1538.300006     6\n",
       "6  Start loop  1522.411878     7\n",
       "6  Start loop  1557.755526     8\n",
       "6  Start loop  1554.391542     9\n",
       "6  Start loop  1541.633949    10"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_for('Start')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Event</th>\n",
       "      <th>Relative</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Criterion</td>\n",
       "      <td>0.068291</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Criterion</td>\n",
       "      <td>0.070115</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Criterion</td>\n",
       "      <td>0.071773</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Criterion</td>\n",
       "      <td>0.072169</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Criterion</td>\n",
       "      <td>0.071828</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Criterion</td>\n",
       "      <td>0.072134</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Criterion</td>\n",
       "      <td>0.071957</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Criterion</td>\n",
       "      <td>0.074589</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Criterion</td>\n",
       "      <td>0.071894</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Criterion</td>\n",
       "      <td>0.071903</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Event  Relative epoch\n",
       "1  Criterion  0.068291     1\n",
       "1  Criterion  0.070115     2\n",
       "1  Criterion  0.071773     3\n",
       "1  Criterion  0.072169     4\n",
       "1  Criterion  0.071828     5\n",
       "1  Criterion  0.072134     6\n",
       "1  Criterion  0.071957     7\n",
       "1  Criterion  0.074589     8\n",
       "1  Criterion  0.071894     9\n",
       "1  Criterion  0.071903    10"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_for('Crit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_sum' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-5def82e9d78e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_sum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Event'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_sum' is not defined"
     ]
    }
   ],
   "source": [
    "df_sum.groupby('Event').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1f8a688cae5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cuda()\n",
    "out, output_sizes = model(inputs, input_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2268,  0.2268],\n",
       "        [-0.5505,  0.5505]], device='cuda:0', grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(np.argmax(out, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "# from collections import OrderedDict\n",
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# from torch.nn.parameter import Parameter\n",
    "# from torch.autograd import Variable\n",
    "\n",
    "# from models.modules import MaskConv, SequenceWise, BatchRNN, InferenceBatchSoftmax, \\\n",
    "#                     supported_rnns, supported_rnns_inv\n",
    "\n",
    "# class AccentClassifier(nn.Module):\n",
    "#     def __init__(self,\n",
    "#                  labels,\n",
    "#                  audio_conf={}, \n",
    "#                  rnn_hidden_size=800, \n",
    "#                  nb_layers=2, \n",
    "#                  rnn_type=nn.GRU):\n",
    "        \n",
    "#         super(AccentClassifier, self).__init__()\n",
    "\n",
    "#         # metadata\n",
    "#         self._audio_conf = audio_conf\n",
    "#         self._labels = labels\n",
    "#         self._num_classes = len(labels)\n",
    "        \n",
    "#         sample_rate = self._audio_conf.get(\"sample_rate\", 16000)\n",
    "#         window_size = self._audio_conf.get(\"window_size\", 0.02)\n",
    "\n",
    "#         self.conv = MaskConv(nn.Sequential(\n",
    "#             nn.Conv2d(1, 32, kernel_size=(41, 11), stride=(2, 2), padding=(20, 5)),\n",
    "#             nn.BatchNorm2d(32),\n",
    "#             nn.Hardtanh(0, 20, inplace=True),\n",
    "#             nn.Conv2d(32, 32, kernel_size=(21, 11), stride=(2, 1), padding=(10, 5)),\n",
    "#             nn.BatchNorm2d(32),\n",
    "#             nn.Hardtanh(0, 20, inplace=True)\n",
    "#         ))\n",
    "\n",
    "#         # Based on above convolutions and spectrogram size using conv formula (W - F + 2P)/ S+1\n",
    "#         rnn_input_size = int(math.floor((sample_rate * window_size) / 2) + 1)\n",
    "#         rnn_input_size = int(math.floor(rnn_input_size + 2 * 20 - 41) / 2 + 1)\n",
    "#         rnn_input_size = int(math.floor(rnn_input_size + 2 * 10 - 21) / 2 + 1)\n",
    "#         rnn_input_size *= 32\n",
    "\n",
    "#         rnns = []\n",
    "#         rnn = BatchRNN(input_size=rnn_input_size, hidden_size=rnn_hidden_size, rnn_type=rnn_type,\n",
    "#                        bidirectional=True, batch_norm=False)\n",
    "#         rnns.append(('0', rnn))\n",
    "#         for x in range(nb_layers - 1):\n",
    "#             rnn = BatchRNN(input_size=rnn_hidden_size, hidden_size=rnn_hidden_size, rnn_type=rnn_type,\n",
    "#                            bidirectional=True)\n",
    "#             rnns.append(('%d' % (x + 1), rnn))\n",
    "            \n",
    "#         self.rnns = nn.Sequential(OrderedDict(rnns))\n",
    "\n",
    "#         fully_connected = nn.Sequential(\n",
    "#             nn.BatchNorm1d(rnn_hidden_size),\n",
    "#             nn.Linear(rnn_hidden_size, self._num_classes, bias=False)\n",
    "#         )\n",
    "#         self.fc = nn.Sequential(\n",
    "#             SequenceWise(fully_connected),\n",
    "#         )\n",
    "#         self.inference_softmax = InferenceBatchSoftmax()\n",
    "\n",
    "\n",
    "#     def forward(self, x, lengths):\n",
    "#         lengths = lengths.cpu().int()\n",
    "#         output_lengths = self.get_seq_lens(lengths)\n",
    "#         x, _ = self.conv(x, output_lengths)\n",
    "#         sizes = x.size()\n",
    "#         x = x.view(sizes[0], sizes[1] * sizes[2], sizes[3])  # Collapse feature dimension\n",
    "#         x = x.transpose(1, 2).transpose(0, 1).contiguous()  # TxNxH\n",
    "\n",
    "#         for rnn in self.rnns:\n",
    "#             x = rnn(x, output_lengths)\n",
    "\n",
    "#         x = self.fc(x)\n",
    "#         x = x.transpose(0, 1)\n",
    "#         # identity in training mode, softmax in eval mode\n",
    "#         x = self.inference_softmax(x)\n",
    "#         return x, output_lengths\n",
    "    \n",
    "#     def get_seq_lens(self, input_length):\n",
    "#         \"\"\"\n",
    "#         Given a 1D Tensor or Variable containing integer sequence lengths, return a 1D tensor or variable\n",
    "#         containing the size sequences that will be output by the network.\n",
    "#         :param input_length: 1D Tensor\n",
    "#         :return: 1D Tensor scaled by model\n",
    "#         \"\"\"\n",
    "#         seq_len = input_length\n",
    "#         for m in self.conv.modules():\n",
    "#             if type(m) == nn.modules.conv.Conv2d:\n",
    "#                 seq_len = ((seq_len + 2 * m.padding[1] - m.dilation[1] * (m.kernel_size[1] - 1) - 1) / m.stride[1] + 1)\n",
    "#         return seq_len.int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AccentClassifier(\n",
       "  (conv): MaskConv(\n",
       "    (seq_module): Sequential(\n",
       "      (0): Conv2d(1, 32, kernel_size=(41, 11), stride=(2, 2), padding=(20, 5))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Hardtanh(min_val=0, max_val=20, inplace)\n",
       "      (3): Conv2d(32, 32, kernel_size=(21, 11), stride=(2, 1), padding=(10, 5))\n",
       "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Hardtanh(min_val=0, max_val=20, inplace)\n",
       "    )\n",
       "  )\n",
       "  (rnns): Sequential(\n",
       "    (0): BatchRNN(\n",
       "      (rnn): GRU(1312, 800, bidirectional=True)\n",
       "    )\n",
       "    (1): BatchRNN(\n",
       "      (batch_norm): SequenceWise (\n",
       "      BatchNorm1d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))\n",
       "      (rnn): GRU(800, 800, bidirectional=True)\n",
       "    )\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): SequenceWise (\n",
       "    Sequential(\n",
       "      (0): BatchNorm1d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Linear(in_features=800, out_features=2, bias=False)\n",
       "    ))\n",
       "  )\n",
       "  (inference_softmax): InferenceBatchSoftmax()\n",
       ")"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = nn.GRU(10, 20, 2)\n",
    "input_ = torch.randn(5, 3, 10)\n",
    "h0 = torch.randn(2, 3, 20)\n",
    "output, hn = rnn(input_, h0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(20, 32, 41, 563)\n",
    "b = torch.randn(20, 32, 41, 420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = a.view(a.size(0), a.size(1) * a.size(2), a.size(3))\n",
    "t = t.transpose(1, 2)\n",
    "t2 = b.view(b.size(0), b.size(1) * b.size(2), b.size(3))\n",
    "t2 = t2.transpose(1, 2)\n",
    "\n",
    "rnn = nn.GRU(32 * 41, 256, 1)\n",
    "output, hn = rnn(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 420, 256])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 420, 256])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hn.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 256])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[:, -1].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.randn(20, 318, 1312)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = nn.ConstantPad2d((0, 0, 2, 2), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 322, 1312])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p(t).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for module in self.seq_module:\n",
    "    x = module(x)\n",
    "    mask = torch.ByteTensor(x.size()).fill_(0)\n",
    "    if x.is_cuda:\n",
    "        mask = mask.cuda()\n",
    "    for i, length in enumerate(lengths):\n",
    "        length = length.item()\n",
    "        if (mask[i].size(2) - length) > 0:\n",
    "            mask[i].narrow(2, length, mask[i].size(2) - length).fill_(1)\n",
    "    x = x.masked_fill(mask, 0)\n",
    "return x, lengths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 318, 1312])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 300, 1312])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.randn(20, 250, 1312)\n",
    "\n",
    "clip = 300\n",
    "if t.size(1) >= clip:\n",
    "    t = t[:, :clip, :]\n",
    "else:\n",
    "    z = torch.zeros(torch.Size((t.size(0), clip - t.size(1), t.size(2))))\n",
    "    z = z.cuda() if t.is_cuda else z\n",
    "    t = torch.cat((t, z), 1)\n",
    "    \n",
    "t.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1, 2, 4])\n",
    "a.narrow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 300, 1312])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.randn(20, 250, 1312)\n",
    "z = torch.zeros(torch.Size((t.size(0), clip - t.size(1), t.size(2))))\n",
    "torch.cat((t, z), 1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
