{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leveraging native language information\n",
    "\n",
    "This notbooks tries to implement a variation of the following paper: [Leveraging Native Language Information for Improved Accented Speech Recognition](https://www.researchgate.net/publication/327388866_Leveraging_Native_Language_Information_for_Improved_Accented_Speech_Recognition).\n",
    "\n",
    "We use a slightly different architecture based on [Sean Naren's Deepspeech implementation](https://github.com/SeanNaren/deepspeech.pytorch).\n",
    "\n",
    "The data splits used for testing are the same as in this paper: [Improved Accented Speech Recognition\n",
    "Using Accent Embeddings and Multi-task Learning](https://www.isca-speech.org/archive/Interspeech_2018/pdfs/1864.pdf).\n",
    "\n",
    "The precise splits can be found [here](https://sites.google.com/view/accentsunearthed-dhvani/home).\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Allows to load modules from parent directory\n",
    "import inspect, sys\n",
    "from os.path import dirname, abspath\n",
    "sys.path.append(dirname(dirname(abspath(inspect.getfile(inspect.currentframe())))))\n",
    "\n",
    "# Imports\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "\n",
    "from utils import Timer, AverageMeter, restricted_float\n",
    "from itertools import product as cross_iter\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm\n",
    "from torch.nn.modules import CrossEntropyLoss\n",
    "from warpctc_pytorch import CTCLoss\n",
    "\n",
    "from data.data_loader import create_binarizer\n",
    "\n",
    "from data.data_loader import AudioDataLoader, SpectrogramAccentDataset, BucketingSampler, DistributedBucketingSampler\n",
    "from data.utils import reduce_tensor\n",
    "from decoder import GreedyDecoder\n",
    "from model import DeepSpeech, supported_rnns\n",
    "from multitask_model import MtAccent\n",
    "from multitask_loss import MtLoss\n",
    "\n",
    "# autoreloads\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure experiments by directly changing the values in parameters.py\n",
    "param = parameters.get_parameters()\n",
    "config = parameters.get_config()\n",
    "\n",
    "def to_np(x):\n",
    "    return x.data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None # TODO\n",
    "# MtAccent(accents_size=len(accent_binarizer.classes_),\n",
    "#                 bottleneck_size=args.bottleneck_size,\n",
    "#                 rnn_hidden_size=args.hidden_size,\n",
    "#                 nb_layers=args.hidden_layers,\n",
    "#                 labels=labels,\n",
    "#                 rnn_type=supported_rnns[rnn_type],\n",
    "#                 audio_conf=audio_conf,\n",
    "#                 bidirectional=args.bidirectional,\n",
    "#                 side_nb_layers=args.side_hidden_layers,\n",
    "#                 side_rnn_hidden_size=args.side_hidden_size,\n",
    "#                 side_rnn_type=supported_rnns[side_rnn_type],\n",
    "#                 nb_shared_layers=args.shared_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-114-55125e3f638e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mloss_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmain_loss_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mside_loss_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "accent_binarizer = create_binarizer(args.train_manifest)\n",
    "\n",
    "avg_loss, start_epoch, start_iter = 0, 0, 0\n",
    "avg_main_loss, avg_side_loss = 0, 0\n",
    "\n",
    "    with open(args.labels_path) as label_file:\n",
    "        labels = str(''.join(json.load(label_file)))\n",
    "\n",
    "    audio_conf = dict(sample_rate=args.sample_rate,\n",
    "                      window_size=args.window_size,\n",
    "                      window_stride=args.window_stride,\n",
    "                      window=args.window,\n",
    "                      noise_dir=args.noise_dir,\n",
    "                      noise_prob=args.noise_prob,\n",
    "                      noise_levels=(args.noise_min, args.noise_max))\n",
    "\n",
    "    rnn_type = args.rnn_type.lower()\n",
    "    assert rnn_type in supported_rnns, \"rnn_type should be either lstm, rnn or gru\"\n",
    "\n",
    "    if args.side_rnn_type is not None:\n",
    "        side_rnn_type = args.side_rnn_type.lower()\n",
    "        assert side_rnn_type in supported_rnns, \"side_rnn_type should be either lstm, rnn or gru\"\n",
    "\n",
    "        \n",
    "\n",
    "    parameters = model.parameters()\n",
    "    if args.optimizer == \"adam\":\n",
    "        optimizer = torch.optim.Adam(parameters, lr=args.lr)\n",
    "    elif args.optimizer == \"sgd\":\n",
    "        optimizer = torch.optim.SGD(parameters, lr=args.lr,\n",
    "                            momentum=args.momentum, nesterov=True)\n",
    "\n",
    "if args.model == 'deepspeech':\n",
    "    criterion = CTCLoss()\n",
    "elif args.model == 'mtaccent':\n",
    "    criterion = MtLoss(CTCLoss(), CrossEntropyLoss(), mixing_coef=args.mixing_coef)\n",
    "\n",
    "decoder = GreedyDecoder(labels)\n",
    "\n",
    "\n",
    "use_kaldi_features = False\n",
    "\n",
    "train_dataset = SpectrogramAccentDataset(audio_conf=audio_conf, \n",
    "                                        manifest_filepath=args.train_manifest, \n",
    "                                        labels=labels,\n",
    "                                        normalize=True, \n",
    "                                        augment=args.augment, \n",
    "                                        accent_binarizer=accent_binarizer,\n",
    "                                        kaldi=use_kaldi_features)\n",
    "\n",
    "test_dataset = SpectrogramAccentDataset(audio_conf=audio_conf, \n",
    "                                        manifest_filepath=args.val_manifest, \n",
    "                                        labels=labels,\n",
    "                                        normalize=True, \n",
    "                                        augment=False, \n",
    "                                        accent_binarizer=accent_binarizer,\n",
    "                                        kaldi=use_kaldi_features) \n",
    "\n",
    "\n",
    "if not args.distributed:\n",
    "    train_sampler = BucketingSampler(train_dataset, batch_size=args.batch_size)\n",
    "else:\n",
    "    train_sampler = DistributedBucketingSampler(train_dataset, batch_size=args.batch_size,\n",
    "                                                num_replicas=args.world_size, rank=args.rank)\n",
    "\n",
    "train_loader = AudioDataLoader(train_dataset,\n",
    "                                num_workers=args.num_workers, \n",
    "                                batch_sampler=train_sampler)\n",
    "test_loader = AudioDataLoader(test_dataset, \n",
    "                                batch_size=args.batch_size,\n",
    "                                num_workers=args.num_workers)\n",
    "\n",
    "\n",
    "if (not args.no_shuffle and start_epoch != 0) or args.no_sorta_grad:\n",
    "    print(\"Shuffling batches for the following epochs\")\n",
    "    train_sampler.shuffle(start_epoch)\n",
    "\n",
    "if args.cuda:\n",
    "    model.cuda()\n",
    "    if args.distributed:\n",
    "        model = torch.nn.parallel.DistributedDataParallel(\n",
    "            model,\n",
    "            device_ids=(int(args.gpu_rank),) if args.rank else None)\n",
    "\n",
    "print(model)\n",
    "print(\"Number of parameters: %d\" % type(model).get_param_size(model))\n",
    "\n",
    "if args.tensorboard and main_proc: # TODO empty scope name problem\n",
    "    try:\n",
    "        dummy_inputs = torch.rand(20, 1, 161, 10) # TODO dynamically change size\n",
    "        if args.cuda:\n",
    "             dummy_inputs = dummy_inputs.cuda()\n",
    "        dummy_size = torch.rand(20)\n",
    "        tensorboard_writer.add_graph(model, (dummy_inputs, dummy_size), verbose=True)\n",
    "    except Exception as e:\n",
    "        print(\"Exception while creating tensorboard graph:\")\n",
    "        print(e)\n",
    "\n",
    "batch_time = AverageMeter()\n",
    "data_time = AverageMeter()\n",
    "losses = AverageMeter()\n",
    "\n",
    "#t.print_report()\n",
    "## TRAIN ##\n",
    "t.add('starts epochs')\n",
    "display_scaling_coef = None\n",
    "for epoch in range(start_epoch, args.epochs):\n",
    "    t.add(f'begin epoch {epoch}')\n",
    "    model.train()\n",
    "    end = time.time()\n",
    "    start_epoch_time = time.time()\n",
    "    for i, (data) in enumerate(train_loader, start=start_iter):\n",
    "        if i == len(train_sampler):\n",
    "            break\n",
    "        inputs, targets, input_percentages, target_sizes, target_accents = data\n",
    "        input_sizes = input_percentages.mul_(int(inputs.size(3))).int()\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        if args.cuda:\n",
    "            inputs = inputs.cuda()\n",
    "        t.add(f'epoch {epoch}, batch {i} forward pass')\n",
    "\n",
    "        if args.model == 'deepspeech':\n",
    "            out, output_sizes = model(inputs, input_sizes)\n",
    "            out = out.transpose(0, 1)  # TxNxH\n",
    "\n",
    "            loss = criterion(out, targets, output_sizes, target_sizes)\n",
    "            main_loss, side_loss = torch.tensor(0), torch.tensor(0)\n",
    "        elif args.model == 'mtaccent':\n",
    "            if epoch != 0:\n",
    "                criterion.toggle_update_coefs(new_value=False)\n",
    "\n",
    "            out, output_sizes, side_out = model(inputs, input_sizes)\n",
    "            out = out.transpose(0, 1)  # TxNxH\n",
    "            target_accents = np.argmax(target_accents, axis=1) # TODO check if this could be done elsewhere…\n",
    "            loss = criterion((out, targets, output_sizes, target_sizes), (side_out.cpu(), target_accents))\n",
    "            main_loss, side_loss = criterion.get_sublosses()\n",
    "\n",
    "\n",
    "        loss = loss / inputs.size(0)  # average the loss by minibatch\n",
    "        main_loss = main_loss / inputs.size(0)\n",
    "        side_loss = side_loss / inputs.size(0)\n",
    "\n",
    "        if args.distributed:\n",
    "            loss_value = reduce_tensor(loss, args.world_size)[0]\n",
    "            main_loss_value = reduce_tensor(main_loss, args.world_size)[0]\n",
    "            side_loss_value = reduce_tensor(side_loss, args.world_size)[0]\n",
    "        else:\n",
    "            loss_value = loss.item()\n",
    "            main_loss_value = main_loss.item()\n",
    "            side_loss_value = side_loss.item()\n",
    "\n",
    "        inf = float(\"inf\")\n",
    "        if loss_value == inf or loss_value == -inf:\n",
    "            print(\"WARNING: received an inf loss, setting loss value to 0\")\n",
    "            loss_value = 0\n",
    "        if main_loss_value == inf or main_loss_value == -inf:\n",
    "            print(\"WARNING: received an inf main_loss, setting loss value to 0\")\n",
    "            main_loss_value = 0\n",
    "        if side_loss_value == inf or side_loss_value == -inf:\n",
    "            print(\"WARNING: received an inf side_loss, setting side_loss value to 0\")\n",
    "            side_loss_value = 0\n",
    "        t.add(f'epoch {epoch} backward pass')\n",
    "\n",
    "        avg_loss += loss_value\n",
    "        avg_main_loss += main_loss_value\n",
    "        avg_side_loss += side_loss_value\n",
    "        losses.update(loss_value, inputs.size(0))\n",
    "\n",
    "        # compute gradient\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_norm)\n",
    "        # Optimizer step\n",
    "        optimizer.step()\n",
    "        t.add('starts computing stuff to print')\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        if not args.silent:\n",
    "            sub_losses = criterion.print_sublosses() if args.model == 'mtaccent' else 'n/a'\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  '(Sub-losses: {sub_losses})\\t'.format(\n",
    "                (epoch + 1), (i + 1), len(train_sampler), \n",
    "                batch_time=batch_time, data_time=data_time, \n",
    "                loss=losses, sub_losses=sub_losses))\n",
    "        if args.checkpoint_per_batch > 0 and i > 0 and (i + 1) % args.checkpoint_per_batch == 0 and main_proc:\n",
    "            file_path = '%s/deepspeech_checkpoint_epoch_%d_iter_%d.pth' % (save_folder, epoch + 1, i + 1)\n",
    "            print(\"Saving checkpoint model to %s\" % file_path)\n",
    "            torch.save(type(model).serialize(model, optimizer=optimizer, epoch=epoch, iteration=i,\n",
    "                                            loss_results=loss_results,\n",
    "                                            main_loss_results=main_loss_results,\n",
    "                                            side_loss_results=side_loss_results,\n",
    "                                            wer_results=wer_results, \n",
    "                                            cer_results=cer_results, \n",
    "                                            mca_results=mca_results,\n",
    "                                            avg_loss=avg_loss,\n",
    "                                            avg_main_loss=avg_main_loss,\n",
    "                                            avg_side_loss=avg_side_loss),\n",
    "                       file_path)\n",
    "        del loss\n",
    "        del out\n",
    "\n",
    "    avg_loss /= len(train_sampler)\n",
    "    avg_main_loss /= len(train_sampler)\n",
    "    avg_side_loss /= len(train_sampler)\n",
    "\n",
    "    if display_scaling_coef is None:\n",
    "        display_scaling_coef = 100. / avg_loss\n",
    "    display_avg_loss = avg_loss * display_scaling_coef\n",
    "    display_avg_main_loss = avg_main_loss * display_scaling_coef\n",
    "    display_avg_side_loss = avg_side_loss * display_scaling_coef\n",
    "\n",
    "    epoch_time = time.time() - start_epoch_time\n",
    "    print('Training Summary Epoch: [{0}]\\t'\n",
    "          'Time taken (s): {epoch_time:.0f}\\t'\n",
    "          'Average Loss {loss:.3f}\\t'.format(epoch + 1, epoch_time=epoch_time, loss=avg_loss))\n",
    "\n",
    "    start_iter = 0  # Reset start iteration for next epoch\n",
    "\n",
    "    ## VALIDATION ##\n",
    "    #t.print_report()\n",
    "    total_cer, total_wer, total_mca = 0, 0, 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (data) in tqdm(enumerate(test_loader), total=len(test_loader)):\n",
    "            inputs, targets, input_percentages, target_sizes, target_accents = data\n",
    "            input_sizes = input_percentages.mul_(int(inputs.size(3))).int()\n",
    "\n",
    "            # unflatten targets\n",
    "            split_targets = []\n",
    "            offset = 0\n",
    "            for size in target_sizes:\n",
    "                split_targets.append(targets[offset:offset + size])\n",
    "                offset += size\n",
    "\n",
    "            if args.cuda:\n",
    "                inputs = inputs.cuda()\n",
    "\n",
    "            if args.model == 'deepspeech':\n",
    "                out, output_sizes = model(inputs, input_sizes)\n",
    "            elif args.model == 'mtaccent':\n",
    "                out, output_sizes, side_out = model(inputs, input_sizes)\n",
    "                mca = 0\n",
    "\n",
    "                for x in range(len(target_accents)):\n",
    "                    accent_out = np.argmax(torch.exp(side_out[x])) # take exp because we do logsoftmax\n",
    "                    accent_target = np.argmax(target_accents[x])\n",
    "\n",
    "                    if accent_out != accent_target:\n",
    "                        mca += 1\n",
    "                total_mca += mca\n",
    "\n",
    "            decoded_output, _ = decoder.decode(out.data, output_sizes)\n",
    "            target_strings = decoder.convert_to_strings(split_targets)\n",
    "            wer, cer = 0, 0\n",
    "            for x in range(len(target_strings)):\n",
    "                transcript, reference = decoded_output[x][0], target_strings[x][0]\n",
    "                wer += decoder.wer(transcript, reference) / float(len(reference.split()))\n",
    "                cer += decoder.cer(transcript, reference) / float(len(reference))\n",
    "            total_cer += cer\n",
    "            total_wer += wer\n",
    "            del out\n",
    "\n",
    "        wer = total_wer / len(test_loader.dataset)\n",
    "        cer = total_cer / len(test_loader.dataset)\n",
    "\n",
    "        wer *= 100\n",
    "        cer *= 100\n",
    "\n",
    "        loss_results[epoch] = display_avg_loss\n",
    "        main_loss_results[epoch] = display_avg_main_loss\n",
    "        side_loss_results[epoch] = display_avg_side_loss\n",
    "        wer_results[epoch] = wer\n",
    "        cer_results[epoch] = cer\n",
    "\n",
    "        if args.model == 'mtaccent':\n",
    "            mca = total_mca / len(test_loader.dataset)\n",
    "            mca *= 100\n",
    "        else:\n",
    "            mca = -1 # if the model doesn't use accent, mca doesn't make sense.\n",
    "        mca_results[epoch] = mca\n",
    "\n",
    "        mca_print = f'{mca:.3f}' if mca != -1 else 'n/a'\n",
    "        print('Validation Summary Epoch: [{0}]\\t'\n",
    "              'Average WER {wer:.3f}\\t'\n",
    "              'Average CER {cer:.3f}\\t'\n",
    "              'Accent missclassification {mca}\\t'.format(epoch + 1, wer=wer, cer=cer, mca=mca_print))\n",
    "\n",
    "        \n",
    "        if args.checkpoint and main_proc:\n",
    "            file_path = '%s/deepspeech_%d.pth' % (save_folder, epoch + 1)\n",
    "            torch.save(type(model).serialize(model, optimizer=optimizer, \n",
    "                                            epoch=epoch, \n",
    "                                            loss_results=loss_results,\n",
    "                                            main_loss_results=main_loss_results,\n",
    "                                            side_loss_results=side_loss_results,\n",
    "                                            wer_results=wer_results, cer_results=cer_results,\n",
    "                                            mca_results=mca_results),\n",
    "                       file_path)\n",
    "            # anneal lr\n",
    "            optim_state = optimizer.state_dict()\n",
    "            optim_state['param_groups'][0]['lr'] = optim_state['param_groups'][0]['lr'] / args.learning_anneal\n",
    "            optimizer.load_state_dict(optim_state)\n",
    "            print('Learning rate annealed to: {lr:.6f}'.format(lr=optim_state['param_groups'][0]['lr']))\n",
    "\n",
    "        if (best_wer is None or best_wer > wer) and main_proc:\n",
    "            print(\"Found better validated model, saving to %s\" % args.model_path)\n",
    "            torch.save(type(model).serialize(model, optimizer=optimizer, \n",
    "                epoch=epoch,\n",
    "                loss_results=loss_results,\n",
    "                main_loss_results=main_loss_results,\n",
    "                side_loss_results=side_loss_results,\n",
    "                wer_results=wer_results, \n",
    "                cer_results=cer_results), args.model_path)\n",
    "            best_wer = wer\n",
    "\n",
    "            avg_loss = 0\n",
    "        if not args.no_shuffle:\n",
    "            print(\"Shuffling batches...\")\n",
    "            train_sampler.shuffle(epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
